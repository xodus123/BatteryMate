"""VLG í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸"""
import sys
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
PROJECT_ROOT = Path(__file__).parent.parent.parent
sys.path.insert(0, str(PROJECT_ROOT))


def test_prompts():
    """í”„ë¡¬í”„íŠ¸ í…ŒìŠ¤íŠ¸"""
    from models.vlg.prompts import GroundingPrompts

    print("=" * 60)
    print("VLG í”„ë¡¬í”„íŠ¸ í…ŒìŠ¤íŠ¸")
    print("=" * 60)

    # CT í”„ë¡¬í”„íŠ¸
    print("\n[CT Porosity í”„ë¡¬í”„íŠ¸]")
    prompts = GroundingPrompts.get_ct_prompts('porosity')
    print(f"  í‚¤ì›Œë“œ: {prompts}")
    print(f"  Grounding í…ìŠ¤íŠ¸: {GroundingPrompts.to_grounding_text(prompts)}")

    print("\n[CT Resin Overflow í”„ë¡¬í”„íŠ¸]")
    prompts = GroundingPrompts.get_ct_prompts('resin_overflow')
    print(f"  í‚¤ì›Œë“œ: {prompts}")

    print("\n[CT ì „ì²´ ê²°í•¨ í”„ë¡¬í”„íŠ¸]")
    prompts = GroundingPrompts.get_ct_prompts('all')
    print(f"  í‚¤ì›Œë“œ: {prompts}")

    # RGB í”„ë¡¬í”„íŠ¸
    print("\n[RGB ì „ì²´ ê²°í•¨ í”„ë¡¬í”„íŠ¸]")
    prompts = GroundingPrompts.get_rgb_prompts('all')
    print(f"  í‚¤ì›Œë“œ: {prompts}")

    print("\nâœ… í”„ë¡¬í”„íŠ¸ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")


def test_inference_mock():
    """ì¶”ë¡  ëª¨ë“ˆ í…ŒìŠ¤íŠ¸ (ëª¨ë¸ ë¡œë“œ ì—†ì´)"""
    from models.vlg.inference import VLGInference, DetectionResult

    print("\n" + "=" * 60)
    print("VLG ì¶”ë¡  ëª¨ë“ˆ í…ŒìŠ¤íŠ¸ (Mock)")
    print("=" * 60)

    # ëª¨ë¸ ì„¤ì • í™•ì¸
    print("\n[ì§€ì› ëª¨ë¸ ì„¤ì •]")
    for model_type, config in VLGInference.MODEL_CONFIGS.items():
        print(f"  - {model_type}:")
        print(f"      Config: {config['config']}")
        print(f"      Weights: {config['weights']}")

    # DetectionResult í…ŒìŠ¤íŠ¸
    print("\n[DetectionResult í…ŒìŠ¤íŠ¸]")
    result = DetectionResult(
        boxes=[[0.1, 0.2, 0.3, 0.4], [0.5, 0.6, 0.7, 0.8]],
        labels=['porosity', 'bubble'],
        scores=[0.85, 0.72],
        phrases=['porosity defect', 'gas bubble'],
    )
    print(f"  ë°•ìŠ¤ ìˆ˜: {len(result.boxes)}")
    print(f"  ë¼ë²¨: {result.labels}")
    print(f"  ì ìˆ˜: {result.scores}")

    print("\nâœ… ì¶”ë¡  ëª¨ë“ˆ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")


def test_inference_with_model():
    """ì‹¤ì œ ëª¨ë¸ë¡œ ì¶”ë¡  í…ŒìŠ¤íŠ¸"""
    try:
        from models.vlg.inference import create_vlg_inference
        from PIL import Image
        import torch

        print("\n" + "=" * 60)
        print("VLG ì‹¤ì œ ì¶”ë¡  í…ŒìŠ¤íŠ¸")
        print("=" * 60)

        # GPU í™•ì¸
        device = 'cuda' if torch.cuda.is_available() else 'cpu'
        print(f"\nì‚¬ìš© ë””ë°”ì´ìŠ¤: {device}")

        # ëª¨ë¸ ë¡œë“œ
        print("\nëª¨ë¸ ë¡œë“œ ì¤‘...")
        vlg = create_vlg_inference(model_type='swinT', device=device)

        # ëª¨ë¸ ì •ë³´
        info = vlg.get_model_info()
        print(f"\n[ëª¨ë¸ ì •ë³´]")
        for key, value in info.items():
            print(f"  - {key}: {value}")

        if not info['model_loaded']:
            print("\nâš ï¸ GroundingDINO ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            print("   ì„¤ì¹˜: pip install groundingdino")
            return

        # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ì°¾ê¸°
        test_images = list(PROJECT_ROOT.glob("data/**/images/*.jpg"))[:3]

        if test_images:
            print(f"\ní…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ {len(test_images)}ê°œ ë°œê²¬")

            for img_path in test_images:
                print(f"\níƒì§€ ì¤‘: {img_path.name}")
                result = vlg.analyze_image(str(img_path), modality='ct')

                print(f"  ì˜ˆì¸¡: {result.get('prediction')}")
                print(f"  ê²°í•¨ ìˆ˜: {result.get('num_defects')}")
                if result.get('defect_types'):
                    print(f"  ê²°í•¨ ìœ í˜•: {result.get('defect_types')}")
                print(f"  ì‹ ë¢°ë„: {result.get('confidence'):.2f}")

                # ì‹œê°í™” (ì„ íƒ)
                # visualized = vlg.visualize(str(img_path), detection)
                # visualized.save(f"/tmp/vlg_result_{img_path.stem}.jpg")
        else:
            print("\ní…ŒìŠ¤íŠ¸í•  ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")

        print("\nâœ… ì‹¤ì œ ì¶”ë¡  í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")

    except Exception as e:
        print(f"\nâš ï¸ ì‹¤ì œ ì¶”ë¡  í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        print("(GroundingDINOê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤)")


def test_visualization():
    """ì‹œê°í™” í…ŒìŠ¤íŠ¸"""
    from models.vlg.inference import VLGInference, DetectionResult
    from PIL import Image

    print("\n" + "=" * 60)
    print("VLG ì‹œê°í™” í…ŒìŠ¤íŠ¸")
    print("=" * 60)

    # ë”ë¯¸ ì´ë¯¸ì§€ ìƒì„±
    dummy_image = Image.new('RGB', (512, 512), color='gray')

    # ë”ë¯¸ íƒì§€ ê²°ê³¼
    detection = DetectionResult(
        boxes=[[0.1, 0.1, 0.3, 0.3], [0.6, 0.6, 0.9, 0.9]],
        labels=['porosity', 'resin_overflow'],
        scores=[0.92, 0.78],
        phrases=['porosity defect', 'resin overflow'],
    )

    # VLG ì¸ìŠ¤í„´ìŠ¤ (ëª¨ë¸ ì—†ì´)
    vlg = VLGInference.__new__(VLGInference)
    vlg.model = None
    vlg.prompts = None

    # ì‹œê°í™”
    output_path = "/tmp/vlg_visualization_test.jpg"
    result_image = vlg.visualize(dummy_image, detection, output_path=output_path)

    print(f"  ì‹œê°í™” ì´ë¯¸ì§€ í¬ê¸°: {result_image.size}")
    print(f"  ì €ì¥ ê²½ë¡œ: {output_path}")

    print("\nâœ… ì‹œê°í™” í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")


def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    import argparse

    parser = argparse.ArgumentParser(description='VLG í…ŒìŠ¤íŠ¸')
    parser.add_argument('--full', action='store_true', help='ëª¨ë¸ ë¡œë“œ í¬í•¨ ì „ì²´ í…ŒìŠ¤íŠ¸')
    parser.add_argument('--viz', action='store_true', help='ì‹œê°í™” í…ŒìŠ¤íŠ¸')
    args = parser.parse_args()

    # ê¸°ë³¸ í…ŒìŠ¤íŠ¸
    test_prompts()
    test_inference_mock()

    # ì‹œê°í™” í…ŒìŠ¤íŠ¸
    if args.viz:
        test_visualization()

    # ì „ì²´ í…ŒìŠ¤íŠ¸ (ëª¨ë¸ ë¡œë“œ í¬í•¨)
    if args.full:
        test_inference_with_model()
    else:
        print("\nğŸ’¡ ì „ì²´ í…ŒìŠ¤íŠ¸ë¥¼ ì‹¤í–‰í•˜ë ¤ë©´ --full ì˜µì…˜ì„ ì‚¬ìš©í•˜ì„¸ìš”")
        print("   python models/vlg/test_vlg.py --full")
        print("   python models/vlg/test_vlg.py --viz  # ì‹œê°í™” í…ŒìŠ¤íŠ¸")


if __name__ == "__main__":
    main()
