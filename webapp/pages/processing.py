"""Page 2: Processing - ì¶”ë¡  ì§„í–‰ ì¤‘ (ì‹¤ì œ ëª¨ë¸ ì—°ë™)"""
import sys
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ sys.pathì— ì¶”ê°€
_project_root = Path(__file__).parent.parent.parent.absolute()
if str(_project_root) not in sys.path:
    sys.path.insert(0, str(_project_root))

import streamlit as st
import time
from PIL import Image
import io
import tempfile
import os

# ì„¤ì • ëª¨ë“ˆ ë¡œë“œ
from config import settings

from webapp.utils.session import (
    navigate_to, set_analysis_result, AnalysisResult
)
from webapp.utils.styles import render_alert


def log(msg: str):
    """í„°ë¯¸ë„ ë¡œê·¸ ì¶œë ¥"""
    print(f"[WEBAPP] {time.strftime('%H:%M:%S')} - {msg}", flush=True)


# ëª¨ë¸ ì‹±ê¸€í†¤ (ì•± ì‹œì‘ ì‹œ í•œ ë²ˆë§Œ ë¡œë“œ)
@st.cache_resource
def load_ensemble_model():
    """ì•™ìƒë¸” ëª¨ë¸ ë¡œë“œ (ìºì‹±)"""
    log("ğŸ”µ Ensemble ëª¨ë¸ ë¡œë“œ ì‹œì‘...")
    from models.ensemble.ensemble import create_ensemble
    try:
        ensemble = create_ensemble()
        log("âœ… Ensemble ëª¨ë¸ ë¡œë“œ ì„±ê³µ!")
        return ensemble, None
    except Exception as e:
        log(f"âŒ Ensemble ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None, str(e)


@st.cache_resource
def load_vlm_model(model_type: str = None):
    """VLM ëª¨ë¸ ë¡œë“œ (ìºì‹±) - Qwen2-VL ë˜ëŠ” Gemini"""
    # ëª¨ë¸ íƒ€ì…ì´ ì§€ì •ë˜ì§€ ì•Šìœ¼ë©´ ì„¤ì •ì—ì„œ ê¸°ë³¸ê°’ ì‚¬ìš©
    if model_type is None:
        model_type = settings.VLM_DEFAULT_MODEL

    log(f"ğŸŸ£ VLM ëª¨ë¸ ë¡œë“œ ì‹œì‘... (ëª¨ë¸: {model_type})")
    try:
        if model_type == 'gemini':
            from models.vlm.inference_gemini import GeminiVLMInference
            # API í‚¤ëŠ” configì—ì„œ ë¡œë“œ
            vlm = GeminiVLMInference(
                api_key=settings.GEMINI_API_KEY,
                model_name=settings.GEMINI_MODEL_NAME
            )
            log("âœ… Gemini VLM ëª¨ë¸ ë¡œë“œ ì„±ê³µ!")
        else:
            from models.vlm.inference import VLMInference
            vlm = VLMInference(model_size=settings.VLM_MODEL_SIZE)
            log("âœ… Qwen2-VL ëª¨ë¸ ë¡œë“œ ì„±ê³µ!")
        return vlm, None
    except Exception as e:
        import traceback
        log(f"âŒ VLM ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None, f"{e}\n{traceback.format_exc()}"


@st.cache_resource
def load_vlg_model(model_type: str = 'groundingdino'):
    """VLG ëª¨ë¸ ë¡œë“œ (ìºì‹±)"""
    log(f"ğŸŸ  VLG ëª¨ë¸ ë¡œë“œ ì‹œì‘... (ëª¨ë¸: {model_type})")
    try:
        if model_type == 'yoloworld':
            from models.vlg.inference_yoloworld import YOLOWorldInference
            vlg = YOLOWorldInference()
            log("âœ… YOLO-World ëª¨ë¸ ë¡œë“œ ì„±ê³µ!")
        else:
            from models.vlg.inference import VLGInference
            vlg = VLGInference()
            log("âœ… GroundingDINO ëª¨ë¸ ë¡œë“œ ì„±ê³µ!")
        return vlg, None
    except Exception as e:
        log(f"âŒ VLG ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None, str(e)


def render():
    """í”„ë¡œì„¸ì‹± í˜ì´ì§€ ë Œë”ë§"""

    # ì´ë¯¸ì§€ í™•ì¸ (CT ë˜ëŠ” RGB ì¤‘ í•˜ë‚˜ë¼ë„ ìˆì–´ì•¼ í•¨)
    ct_image = st.session_state.get('ct_image')
    rgb_image = st.session_state.get('rgb_image')
    analysis_mode = st.session_state.get('analysis_mode', 'ct_only')

    if ct_image is None and rgb_image is None:
        navigate_to('home')
        return

    # ì´ë¯¸ì§€ í‘œì‹œ ì˜ì—­ êµ¬ì„±
    _render_images(ct_image, rgb_image, analysis_mode)

    st.markdown("<br>", unsafe_allow_html=True)

    # ë¶„ì„ ì§„í–‰
    _run_analysis(ct_image, rgb_image, analysis_mode)


def _render_images(ct_image, rgb_image, analysis_mode):
    """ì—…ë¡œë“œëœ ì´ë¯¸ì§€ í‘œì‹œ"""

    if analysis_mode == 'ensemble':
        # 2ì»¬ëŸ¼: CT | RGB
        col1, col2 = st.columns(2)

        with col1:
            st.markdown("""
            <div class="card" style="text-align: center; padding: 0.5rem;">
                <div style="font-size: 0.9rem; color: #666; margin-bottom: 0.5rem;">ğŸ”¬ CT Image (ë‚´ë¶€)</div>
            </div>
            """, unsafe_allow_html=True)
            if ct_image:
                image = Image.open(io.BytesIO(ct_image))
                st.image(image, width="stretch")

        with col2:
            st.markdown("""
            <div class="card" style="text-align: center; padding: 0.5rem;">
                <div style="font-size: 0.9rem; color: #666; margin-bottom: 0.5rem;">ğŸ“· RGB Image (ì™¸ë¶€)</div>
            </div>
            """, unsafe_allow_html=True)
            if rgb_image:
                image = Image.open(io.BytesIO(rgb_image))
                st.image(image, width="stretch")

    elif analysis_mode == 'ct_only' and ct_image:
        # CTë§Œ
        col1, col2, col3 = st.columns([1, 2, 1])
        with col2:
            st.markdown("""
            <div class="card" style="text-align: center; padding: 0.5rem;">
                <div style="font-size: 0.9rem; color: #666; margin-bottom: 0.5rem;">ğŸ”¬ CT Image (ë‚´ë¶€ ê²€ì‚¬)</div>
            </div>
            """, unsafe_allow_html=True)
            image = Image.open(io.BytesIO(ct_image))
            st.image(image, width="stretch")

    elif analysis_mode == 'rgb_only' and rgb_image:
        # RGBë§Œ
        col1, col2, col3 = st.columns([1, 2, 1])
        with col2:
            st.markdown("""
            <div class="card" style="text-align: center; padding: 0.5rem;">
                <div style="font-size: 0.9rem; color: #666; margin-bottom: 0.5rem;">ğŸ“· RGB Image (ì™¸ë¶€ ê²€ì‚¬)</div>
            </div>
            """, unsafe_allow_html=True)
            image = Image.open(io.BytesIO(rgb_image))
            st.image(image, width="stretch")


def _save_temp_image(image_bytes: bytes, prefix: str = "temp") -> str:
    """ì´ë¯¸ì§€ ë°”ì´íŠ¸ë¥¼ ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥"""
    with tempfile.NamedTemporaryFile(delete=False, suffix=".png", prefix=prefix) as f:
        image = Image.open(io.BytesIO(image_bytes))
        image.save(f.name)
        return f.name


def _run_analysis(ct_image, rgb_image, analysis_mode):
    """ë¶„ì„ ì‹¤í–‰"""

    # ìƒíƒœ ë©”ì‹œì§€ ì»¨í…Œì´ë„ˆ
    status_container = st.container()

    with status_container:
        # ëª¨ë“œë³„ ì•ˆë‚´ ë©”ì‹œì§€
        if analysis_mode == 'ensemble':
            mode_msg = "ğŸ”— ì•™ìƒë¸” ë¶„ì„ - CT (ë‚´ë¶€) + RGB (ì™¸ë¶€) ì¢…í•© íŒì •"
        elif analysis_mode == 'ct_only':
            mode_msg = "ğŸ”¬ CT ë¶„ì„ - ë‚´ë¶€ ê²°í•¨ ê²€ì‚¬"
        else:
            mode_msg = "ğŸ“· RGB ë¶„ì„ - ì™¸ë¶€ ê²°í•¨ ê²€ì‚¬"

        st.markdown(
            render_alert(f"ì´ë¯¸ì§€ ì—…ë¡œë“œ ì™„ë£Œ. {mode_msg}", "info", "âœ…"),
            unsafe_allow_html=True
        )

        # ì„ì‹œ íŒŒì¼ë¡œ ì´ë¯¸ì§€ ì €ì¥
        ct_path = None
        rgb_path = None

        if ct_image:
            ct_path = _save_temp_image(ct_image, "ct_")
        if rgb_image:
            rgb_path = _save_temp_image(rgb_image, "rgb_")

        try:
            # ë¶„ì„ ì§„í–‰
            progress_placeholder = st.empty()

            # 3ê°œ ëª¨ë¸ ë¶„ì„
            models = [
                ('ensemble', 'Ensemble System', 'ì•™ìƒë¸” (CNN + AE)'),
                ('vlm', 'VLM System', 'VLM (Qwen2-VL)'),
                ('vlg', 'VLG System', 'VLG (GroundingDINO)'),
            ]

            for i, (model_id, model_name, model_desc) in enumerate(models):
                with progress_placeholder.container():
                    st.markdown(f"""
                    <div class="alert-box alert-info" style="background: #FFF3E0; border-left-color: #FF9800; color: #E65100;">
                        <span>â³</span>
                        <span>{model_desc} ë¶„ì„ ì¤‘... ({i+1}/3)</span>
                    </div>
                    """, unsafe_allow_html=True)

                # ë¶„ì„ ì‹¤í–‰
                result = _run_inference(model_id, ct_path, rgb_path, analysis_mode)
                set_analysis_result(model_id, result)

            # ì™„ë£Œ ë©”ì‹œì§€
            progress_placeholder.empty()

            st.markdown(
                render_alert("ëª¨ë“  ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!", "success", "âœ¨"),
                unsafe_allow_html=True
            )

        finally:
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
            if ct_path and os.path.exists(ct_path):
                os.remove(ct_path)
            if rgb_path and os.path.exists(rgb_path):
                os.remove(rgb_path)

        st.markdown("<br>", unsafe_allow_html=True)

        # ê²°ê³¼ ë³´ê¸° ë²„íŠ¼
        if st.button("â± ë¹„êµ ëŒ€ì‹œë³´ë“œ ê²°ê³¼ ë³´ê¸°", width="stretch"):
            st.session_state.analysis_complete = True
            navigate_to('summary')


def _run_inference(model_id: str, ct_path: str, rgb_path: str, analysis_mode: str) -> AnalysisResult:
    """
    ëª¨ë¸ ì¶”ë¡  ì‹¤í–‰

    Args:
        model_id: ëª¨ë¸ ID (ensemble, vlm, vlg)
        ct_path: CT ì´ë¯¸ì§€ ì„ì‹œ íŒŒì¼ ê²½ë¡œ
        rgb_path: RGB ì´ë¯¸ì§€ ì„ì‹œ íŒŒì¼ ê²½ë¡œ
        analysis_mode: ë¶„ì„ ëª¨ë“œ (ensemble, ct_only, rgb_only)

    Returns:
        AnalysisResult
    """
    if model_id == 'ensemble':
        return _run_ensemble_inference(ct_path, rgb_path, analysis_mode)

    elif model_id == 'vlm':
        return _run_vlm_inference(ct_path, rgb_path, analysis_mode)

    elif model_id == 'vlg':
        return _run_vlg_inference(ct_path, rgb_path, analysis_mode)

    return AnalysisResult(
        model_name='Unknown',
        prediction='unknown',
        confidence=0.0,
    )


def _run_ensemble_inference(ct_path: str, rgb_path: str, analysis_mode: str) -> AnalysisResult:
    """
    ì•™ìƒë¸” ì¶”ë¡  (CT CNN + RGB AE) - ì‹¤ì œ ëª¨ë¸ ì‚¬ìš©
    """
    import time
    start_time = time.time()

    log("ğŸ”µ Ensemble ì¶”ë¡  ì‹œì‘...")

    # ëª¨ë¸ ë¡œë“œ
    ensemble, error = load_ensemble_model()

    if error:
        # ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨ ì‹œ ì—ëŸ¬ ê²°ê³¼ ë°˜í™˜
        log(f"âŒ Ensemble ëª¨ë¸ ì‚¬ìš© ë¶ˆê°€: {error}")
        return AnalysisResult(
            model_name='Ensemble System',
            prediction='error',
            confidence=0.0,
            defect_type=None,
            details={'error': error, 'mode': analysis_mode},
            inference_time=0.0,
        )

    try:
        # ë¶„ì„ ëª¨ë“œì— ë”°ë¥¸ ì¶”ë¡  (ì‹œê°í™” í¬í•¨)
        visualizations = None

        if analysis_mode == 'ensemble' and ct_path and rgb_path:
            # ì•™ìƒë¸”: Grad-CAM + Error Map í¬í•¨
            result = ensemble.predict_with_visualization(ct_path, rgb_path)
            visualizations = result.get('visualizations')
        elif analysis_mode == 'ct_only' and ct_path:
            # CT only: Grad-CAM í¬í•¨
            ct_result_with_gradcam = ensemble.ct_predictor.predict_with_gradcam(ct_path)
            result = ensemble.predict_ct_only(ct_path)
            result['ct_result'] = ct_result_with_gradcam
            visualizations = {
                'ct_gradcam_overlay': ct_result_with_gradcam['gradcam']['overlay'],
                'ct_gradcam_heatmap': ct_result_with_gradcam['gradcam']['heatmap_colored'],
                'ct_original': ct_result_with_gradcam['gradcam']['original'],
            }
        elif analysis_mode == 'rgb_only' and rgb_path:
            # RGB only: Error Map í¬í•¨
            result = ensemble.predict_rgb_only(rgb_path)
            rgb_original, rgb_reconstructed, rgb_error_map = ensemble.get_rgb_reconstruction(rgb_path)
            visualizations = {
                'rgb_original': rgb_original,
                'rgb_reconstructed': rgb_reconstructed,
                'rgb_error_map': rgb_error_map,
            }
        else:
            # ì´ë¯¸ì§€ê°€ ì—†ëŠ” ê²½ìš°
            return AnalysisResult(
                model_name='Ensemble System',
                prediction='error',
                confidence=0.0,
                details={'error': 'ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.', 'mode': analysis_mode},
                inference_time=0.0,
            )

        inference_time = time.time() - start_time

        # ê²°ê³¼ ë³€í™˜
        verdict = result.get('verdict', 'ì•Œ ìˆ˜ ì—†ìŒ')
        verdict_en = result.get('verdict_en', 'unknown')
        confidence = result.get('confidence', 0.0)

        # ê²°í•¨ ìœ í˜• ì¶”ì¶œ
        defect_type = None
        if result.get('ct_result') and result['ct_result'].get('is_defect'):
            defect_type = result['ct_result'].get('class_name')
        if result.get('rgb_result') and result['rgb_result'].get('is_defect'):
            if defect_type:
                defect_type += " + ì™¸ê´€ì´ìƒ"
            else:
                defect_type = "ì™¸ê´€ì´ìƒ (ì˜¤ì—¼/ì†ìƒ)"

        log(f"âœ… Ensemble ì¶”ë¡  ì™„ë£Œ: {verdict} (ì‹ ë¢°ë„: {confidence:.1%})")
        return AnalysisResult(
            model_name='Ensemble System',
            prediction=verdict_en,
            confidence=confidence,
            defect_type=defect_type,
            details={
                'verdict': verdict,
                'verdict_en': verdict_en,
                'mode': analysis_mode,
                'ct_result': result.get('ct_result'),
                'rgb_result': result.get('rgb_result'),
                'visualizations': visualizations,  # ì‹¤ì œ Grad-CAM/Error Map
            },
            inference_time=inference_time,
        )

    except Exception as e:
        log(f"âŒ Ensemble ì¶”ë¡  ì˜¤ë¥˜: {e}")
        return AnalysisResult(
            model_name='Ensemble System',
            prediction='error',
            confidence=0.0,
            details={'error': str(e), 'mode': analysis_mode},
            inference_time=0.0,
        )


def _run_vlm_inference(ct_path: str, rgb_path: str, analysis_mode: str) -> AnalysisResult:
    """
    VLM ì¶”ë¡  (Qwen2-VL ë˜ëŠ” Gemini) - ì‹¤ì œ ëª¨ë¸ ì‚¬ìš©
    """
    import time
    start_time = time.time()

    # ì„ íƒëœ VLM ëª¨ë¸ íƒ€ì… ê°€ì ¸ì˜¤ê¸°
    vlm_model_type = st.session_state.get('vlm_model_type', 'qwen2vl')
    model_display_name = 'Gemini 2.0 Flash' if vlm_model_type == 'gemini' else 'Qwen2-VL-2B'

    log(f"ğŸŸ£ VLM ì¶”ë¡  ì‹œì‘... (ëª¨ë¸: {model_display_name})")

    # ëª¨ë¸ ë¡œë“œ ì‹œë„
    vlm, error = load_vlm_model(vlm_model_type)

    if error or vlm is None:
        # ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨ ì‹œ ì—ëŸ¬ ë°˜í™˜ (ë”ë¯¸ ê²°ê³¼ X)
        log(f"âŒ VLM ëª¨ë¸ ì‚¬ìš© ë¶ˆê°€: {error}")
        return AnalysisResult(
            model_name=f'VLM System ({model_display_name})',
            prediction='error',
            confidence=0.0,
            defect_type=None,
            details={
                'error': error or 'VLM ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨',
                'analysis_mode': analysis_mode,
                'model_version': f'{model_display_name} (ë¯¸ë¡œë“œ)',
                'vlm_model': vlm_model_type,
            },
            inference_time=time.time() - start_time,
        )

    # ì‹¤ì œ VLM ì¶”ë¡ 
    try:
        ct_analysis = None
        rgb_analysis = None

        # CT ì´ë¯¸ì§€ ë¶„ì„
        if ct_path:
            ct_result = vlm.analyze_image(ct_path, modality='ct')
            ct_analysis = {
                'prediction': 'defect' if not ct_result.get('is_normal', True) else 'normal',
                'confidence': ct_result.get('confidence', 80),
                'defect_type': ct_result.get('defect_type'),
                'explanation': ct_result.get('raw_response', 'ë¶„ì„ ì™„ë£Œ'),
                'location': ct_result.get('location'),
                'modality': 'ct',
            }

        # RGB ì´ë¯¸ì§€ ë¶„ì„
        if rgb_path:
            rgb_result = vlm.analyze_image(rgb_path, modality='rgb')
            rgb_analysis = {
                'prediction': 'defect' if not rgb_result.get('is_normal', True) else 'normal',
                'confidence': rgb_result.get('confidence', 80),
                'defect_type': rgb_result.get('defect_type'),
                'explanation': rgb_result.get('raw_response', 'ë¶„ì„ ì™„ë£Œ'),
                'location': rgb_result.get('location'),
                'modality': 'rgb',
            }

        inference_time = time.time() - start_time

        # ì¢…í•© íŒì • (ë‚´ë¶€/ì™¸ë¶€/ë³µí•©ë¶ˆëŸ‰ êµ¬ë¶„)
        ct_is_defect = ct_analysis and ct_analysis['prediction'] == 'defect'
        rgb_is_defect = rgb_analysis and rgb_analysis['prediction'] == 'defect'

        explanation = ""
        defect_type = None
        confidence = 0.0

        # prediction ê²°ì •: normal, internal_defect, external_defect, complex_defect
        if ct_is_defect and rgb_is_defect:
            prediction = 'complex_defect'
            verdict = 'ë³µí•©ë¶ˆëŸ‰'
            defect_type = f"{ct_analysis['defect_type'] or 'ë‚´ë¶€ê²°í•¨'} + {rgb_analysis['defect_type'] or 'ì™¸ë¶€ê²°í•¨'}"
        elif ct_is_defect:
            prediction = 'internal_defect'
            verdict = 'ë‚´ë¶€ë¶ˆëŸ‰'
            defect_type = ct_analysis['defect_type']
        elif rgb_is_defect:
            prediction = 'external_defect'
            verdict = 'ì™¸ë¶€ë¶ˆëŸ‰'
            defect_type = rgb_analysis['defect_type'] or 'ì™¸ê´€ì´ìƒ'
        else:
            prediction = 'normal'
            verdict = 'ì •ìƒ'

        # explanation & confidence
        if ct_analysis and rgb_analysis:
            explanation = f"[CT ë¶„ì„]\n{ct_analysis['explanation']}\n\n[RGB ë¶„ì„]\n{rgb_analysis['explanation']}"
            confidence = ((ct_analysis.get('confidence') or 80) + (rgb_analysis.get('confidence') or 80)) / 200.0
        elif ct_analysis:
            explanation = ct_analysis['explanation']
            confidence = (ct_analysis.get('confidence') or 80) / 100.0
        elif rgb_analysis:
            explanation = rgb_analysis['explanation']
            confidence = (rgb_analysis.get('confidence') or 80) / 100.0

        log(f"âœ… VLM ì¶”ë¡  ì™„ë£Œ ({model_display_name}): {verdict} (ì‹ ë¢°ë„: {confidence:.1%})")
        return AnalysisResult(
            model_name=f'VLM System ({model_display_name})',
            prediction=prediction,
            confidence=confidence,
            defect_type=defect_type,
            details={
                'verdict': verdict,
                'explanation': explanation,
                'ct_analysis': ct_analysis,
                'rgb_analysis': rgb_analysis,
                'analysis_mode': analysis_mode,
                'model_version': model_display_name,
                'vlm_model': vlm_model_type,
            },
            inference_time=inference_time,
        )

    except Exception as e:
        import traceback
        log(f"âŒ VLM ì¶”ë¡  ì˜¤ë¥˜: {e}")
        return AnalysisResult(
            model_name=f'VLM System ({model_display_name})',
            prediction='error',
            confidence=0.0,
            details={'error': str(e), 'traceback': traceback.format_exc(), 'vlm_model': vlm_model_type},
            inference_time=time.time() - start_time,
        )


def _run_vlg_inference(ct_path: str, rgb_path: str, analysis_mode: str) -> AnalysisResult:
    """
    VLG ì¶”ë¡  (GroundingDINO ë˜ëŠ” YOLO-World) - ì‹¤ì œ ëª¨ë¸ ì‚¬ìš©
    """
    import time
    start_time = time.time()

    # ì„ íƒëœ VLG ëª¨ë¸ íƒ€ì… ê°€ì ¸ì˜¤ê¸°
    vlg_model_type = st.session_state.get('vlg_model_type', 'groundingdino')
    model_display_name = 'YOLO-World' if vlg_model_type == 'yoloworld' else 'GroundingDINO'

    log(f"ğŸŸ  VLG ì¶”ë¡  ì‹œì‘... (ëª¨ë¸: {model_display_name})")

    # ëª¨ë¸ ë¡œë“œ ì‹œë„
    vlg, error = load_vlg_model(vlg_model_type)

    if error or vlg is None:
        # ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨ ì‹œ ì—ëŸ¬ ë°˜í™˜ (ë”ë¯¸ ê²°ê³¼ X)
        log(f"âŒ VLG ëª¨ë¸ ì‚¬ìš© ë¶ˆê°€: {error}")
        return AnalysisResult(
            model_name=f'VLG System ({model_display_name})',
            prediction='error',
            confidence=0.0,
            defect_type=None,
            details={
                'error': error or 'VLG ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨',
                'num_detections': 0,
                'detections': [],
                'analysis_mode': analysis_mode,
                'vlg_model': vlg_model_type,
            },
            inference_time=time.time() - start_time,
        )

    # ì‹¤ì œ VLG ì¶”ë¡ 
    try:
        all_detections = []
        ct_detections = None
        rgb_detections = None

        # CT ê²°í•¨ íƒì§€
        if ct_path:
            ct_result = vlg.detect(
                ct_path,
                text_prompt="porosity . void . bubble . crack . resin overflow",
                modality='ct',
            )
            # DetectionResult ë°ì´í„°í´ë˜ìŠ¤ì—ì„œ ì†ì„± ì ‘ê·¼
            ct_detections = {
                'num_detections': len(ct_result.boxes),
                'detections': [
                    {
                        'label': ct_result.labels[i] if i < len(ct_result.labels) else 'defect',
                        'score': float(ct_result.scores[i]) if i < len(ct_result.scores) else 0.5,
                        'bbox': ct_result.boxes[i],
                    }
                    for i in range(len(ct_result.boxes))
                ],
                'modality': 'ct',
            }
            for det in ct_detections['detections']:
                all_detections.append({**det, 'source': 'ct'})

        # RGB ê²°í•¨ íƒì§€
        if rgb_path:
            rgb_result = vlg.detect(
                rgb_path,
                text_prompt="pollution . contamination . scratch . damage . stain",
                modality='rgb',
            )
            # DetectionResult ë°ì´í„°í´ë˜ìŠ¤ì—ì„œ ì†ì„± ì ‘ê·¼
            rgb_detections = {
                'num_detections': len(rgb_result.boxes),
                'detections': [
                    {
                        'label': rgb_result.labels[i] if i < len(rgb_result.labels) else 'defect',
                        'score': float(rgb_result.scores[i]) if i < len(rgb_result.scores) else 0.5,
                        'bbox': rgb_result.boxes[i],
                    }
                    for i in range(len(rgb_result.boxes))
                ],
                'modality': 'rgb',
            }
            for det in rgb_detections['detections']:
                all_detections.append({**det, 'source': 'rgb'})

        inference_time = time.time() - start_time

        total = len(all_detections)
        max_score = max([d['score'] for d in all_detections], default=0.0)

        # CT/RGB ê²€ì¶œ ì—¬ë¶€ í™•ì¸
        ct_has_defect = ct_detections and ct_detections.get('num_detections', 0) > 0
        rgb_has_defect = rgb_detections and rgb_detections.get('num_detections', 0) > 0

        # prediction ê²°ì •: normal, internal_defect, external_defect, complex_defect
        if ct_has_defect and rgb_has_defect:
            prediction = 'complex_defect'
            verdict = 'ë³µí•©ë¶ˆëŸ‰'
            ct_labels = [d['label'] for d in ct_detections.get('detections', [])]
            rgb_labels = [d['label'] for d in rgb_detections.get('detections', [])]
            defect_type = f"{ct_labels[0] if ct_labels else 'ë‚´ë¶€ê²°í•¨'} + {rgb_labels[0] if rgb_labels else 'ì™¸ë¶€ê²°í•¨'}"
        elif ct_has_defect:
            prediction = 'internal_defect'
            verdict = 'ë‚´ë¶€ë¶ˆëŸ‰'
            ct_labels = [d['label'] for d in ct_detections.get('detections', [])]
            defect_type = ct_labels[0] if ct_labels else 'ë‚´ë¶€ê²°í•¨'
        elif rgb_has_defect:
            prediction = 'external_defect'
            verdict = 'ì™¸ë¶€ë¶ˆëŸ‰'
            rgb_labels = [d['label'] for d in rgb_detections.get('detections', [])]
            defect_type = rgb_labels[0] if rgb_labels else 'ì™¸ë¶€ê²°í•¨'
        else:
            prediction = 'normal'
            verdict = 'ì •ìƒ'
            defect_type = None

        log(f"âœ… VLG ì¶”ë¡  ì™„ë£Œ ({model_display_name}): {verdict} - {total}ê°œ ê²€ì¶œ (ìµœëŒ€ ì‹ ë¢°ë„: {max_score:.1%})")
        return AnalysisResult(
            model_name=f'VLG System ({model_display_name})',
            prediction=prediction,
            confidence=max_score,
            defect_type=defect_type,
            details={
                'verdict': verdict,
                'num_detections': total,
                'detections': all_detections,
                'ct_detections': ct_detections,
                'rgb_detections': rgb_detections,
                'analysis_mode': analysis_mode,
                'text_prompt': 'porosity . void . pollution . scratch . damage',
                'vlg_model': vlg_model_type,
            },
            inference_time=inference_time,
        )

    except Exception as e:
        log(f"âŒ VLG ì¶”ë¡  ì˜¤ë¥˜: {e}")
        return AnalysisResult(
            model_name=f'VLG System ({model_display_name})',
            prediction='error',
            confidence=0.0,
            details={'error': str(e), 'vlg_model': vlg_model_type},
            inference_time=time.time() - start_time,
        )
