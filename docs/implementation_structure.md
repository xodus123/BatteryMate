# ë°°í„°ë¦¬ ê²€ì‚¬ í”„ë¡œì íŠ¸ êµ¬í˜„ êµ¬ì¡° (Web ê¸°ë°˜ + í†µí•© ê²€ì‚¬)

> **ì‘ì„±ì¼**: 2025-12-28 (ìˆ˜ì •: 2026-01-05)
> **í˜„ì¬ Phase**: Phase 3 - CT CNN í•™ìŠµ ì¤‘ + VLM/VLG êµ¬í˜„ ì™„ë£Œ + Webapp êµ¬í˜„ ì™„ë£Œ
> **ê¸°ë°˜ ë¬¸ì„œ**: vision_pipeline_design.md + config_and_evaluation_design.md + inspector_design.md
> **í•µì‹¬**: CT í†µí•© CNN + RGB AE í†µí•© ê²€ì‚¬ ì‹œìŠ¤í…œ vs VLM/VLG ì„±ëŠ¥ ë¹„êµ

---

## ğŸ“‹ ì„¤ê³„ ë¬¸ì„œ í•µì‹¬ ë¶„ì„

### ì„¤ê³„ í•µì‹¬ êµ¬ì¡°

| í•­ëª© | ì„¤ëª… |
|------|------|
| **CT í†µí•© CNN** | Cell + Module í†µí•© 5í´ë˜ìŠ¤ ë¶„ë¥˜ (ë‚´ë¶€ ê²°í•¨ íƒì§€) |
| **RGB AE** | AutoEncoder ê¸°ë°˜ ì™¸ë¶€ ê²°í•¨ ì´ìƒíƒì§€ (ì •ìƒ vs ë¶ˆëŸ‰) |
| **í†µí•© ê²€ì‚¬ ì‹œìŠ¤í…œ** | CT CNN + RGB AE â†’ ë‚´ë¶€ë¶ˆëŸ‰/ì™¸ë¶€ë¶ˆëŸ‰ ì¢…í•© íŒì • |
| **ë¹„êµ ëŒ€ìƒ** | VLM (Qwen3-VL), VLG (GroundingDINO) |
| **í†µí•© ê²€ì‚¬ ëŒ€ìƒ** | CT âˆ© RGB ê²¹ì¹˜ëŠ” 74ê°œ ë°°í„°ë¦¬ |
| **Config ê´€ë¦¬** | YAML íŒŒì¼ (í†µí•© ê²€ì‚¬ ê°€ì¤‘ì¹˜ í¬í•¨) |

### ë°ì´í„° ë¶„í•  êµ¬ì¡° (2026-01-03 í™•ì •)

| ë°ì´í„°ì…‹ | í´ë˜ìŠ¤ ìˆ˜ | ë°°í„°ë¦¬ ìˆ˜ | Train | Val | Test |
|----------|-----------|-----------|-------|-----|------|
| **CT í†µí•©** | 5 | 134 | 138,316 | 26,662 | 36,424 |
| **RGB** | 2 (ì´ìƒíƒì§€) | 300 (ìƒ˜í”Œ) | 35,919 | 11,625 | 11,719 |
| **í†µí•© ê²€ì‚¬** | - | 74 | 51/11/12 ë°°í„°ë¦¬ | - | - |

**CT 5í´ë˜ìŠ¤**: cell_normal, cell_porosity, module_normal, module_porosity, module_resin_overflow
**RGB ì´ìƒíƒì§€**: normal vs defect (AutoEncoder ê¸°ë°˜)

### í•µì‹¬ ì„¤ê³„ ì² í•™

1. **"CT Cell + Moduleì„ í†µí•© CNNìœ¼ë¡œ, RGBëŠ” AEë¡œ í•™ìŠµí•˜ê³  í†µí•© ê²€ì‚¬ë¡œ ë‚´ë¶€/ì™¸ë¶€ ë¶ˆëŸ‰ì„ ì¢…í•© íŒì •í•œë‹¤."**
   - CT CNN: ë‚´ë¶€ ê²°í•¨ ë¶„ë¥˜ (Cell/Module í†µí•©)
   - RGB AE: ì™¸ë¶€ ê²°í•¨ íƒì§€ (ì˜¤ì—¼/ì†ìƒ)
   - í†µí•© ê²€ì‚¬: ë‘ ê²°ê³¼ ì¢…í•© â†’ "ë‚´ë¶€ë¶ˆëŸ‰" / "ì™¸ë¶€ë¶ˆëŸ‰" / "ë³µí•©ë¶ˆëŸ‰" íŒì •

2. **"ì½”ë“œëŠ” ê³ ì •í•˜ê³ , ì‹¤í—˜ì€ ì„¤ì •ìœ¼ë¡œ ë°”ê¾¼ë‹¤"**
   - í†µí•© ê²€ì‚¬ ê°€ì¤‘ì¹˜, Threshold, metricì€ **YAML ì„¤ì •**
   - ë™ì¼ config â†’ ë™ì¼ ê²°ê³¼ ì¬í˜„ ê°€ëŠ¥

3. **"ì‹¤í—˜ì€ ì„¤ì •ìœ¼ë¡œ, íŒë‹¨ì€ ì§€í‘œë¡œ, ê²°ê³¼ëŠ” ë¡œê·¸ë¡œ ë‚¨ê¸´ë‹¤"**

---

## ğŸ—ï¸ ì „ì²´ íŒŒì´í”„ë¼ì¸ êµ¬ì¡°

```
[ë°°í„°ë¦¬ ì´ë¯¸ì§€ ì…ë ¥: CT + RGB]
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  System 1: CT CNN + RGB AE í†µí•© ê²€ì‚¬                        â”‚
â”‚  â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”  â”‚
â”‚                                                          â”‚
â”‚  [CT ì´ë¯¸ì§€] â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ [RGB ì´ë¯¸ì§€]             â”‚
â”‚       â†“                              â†“                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚  CT í†µí•© CNN        â”‚    â”‚  RGB AutoEncoder   â”‚      â”‚
â”‚  â”‚  (ResNet18)         â”‚    â”‚  (CAE)             â”‚      â”‚
â”‚  â”‚                     â”‚    â”‚                    â”‚      â”‚
â”‚  â”‚  5í´ë˜ìŠ¤ ë¶„ë¥˜:      â”‚    â”‚  ì´ìƒíƒì§€ (Binary):â”‚      â”‚
â”‚  â”‚  - cell_normal      â”‚    â”‚  - normal          â”‚      â”‚
â”‚  â”‚  - cell_porosity    â”‚    â”‚  - defect          â”‚      â”‚
â”‚  â”‚  - module_normal    â”‚    â”‚                    â”‚      â”‚
â”‚  â”‚  - module_porosity  â”‚    â”‚  (Reconstruction   â”‚      â”‚
â”‚  â”‚  - module_resin_overflow â”‚   Error ê¸°ë°˜)     â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚       â†“                              â†“                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚  Grad-CAM          â”‚    â”‚  Anomaly Heatmap   â”‚      â”‚
â”‚  â”‚  â†’ ë‚´ë¶€ ê²°í•¨ ìœ„ì¹˜   â”‚    â”‚  â†’ ì™¸ë¶€ ê²°í•¨ ìœ„ì¹˜  â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚       â†“                              â†“                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚           í†µí•© ê²€ì‚¬ ì¢…í•© íŒì • ë ˆì´ì–´              â”‚     â”‚
â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€     â”‚     â”‚
â”‚  â”‚  CT ê²°ê³¼ + RGB ê²°ê³¼ â†’ ìµœì¢… íŒì •                â”‚     â”‚
â”‚  â”‚                                                â”‚     â”‚
â”‚  â”‚  ì¶œë ¥ ì˜ˆì‹œ:                                    â”‚     â”‚
â”‚  â”‚  - "ë‚´ë¶€ë¶ˆëŸ‰ (cell_porosity)" + Grad-CAM       â”‚     â”‚
â”‚  â”‚  - "ì™¸ë¶€ë¶ˆëŸ‰" + Anomaly Heatmap                â”‚     â”‚
â”‚  â”‚  - "ë³µí•©ë¶ˆëŸ‰" + ì–‘ìª½ ì‹œê°í™”                    â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         VS (ë¹„êµ)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  System 2: VLM (Qwen2-VL)                                â”‚
â”‚  â†’ Zero-shot íŒì • + ë¶ˆëŸ‰ ì›ì¸ ì„¤ëª…                       â”‚
â”‚  â†’ Grounding: ë¶ˆëŸ‰ ìœ„ì¹˜ BBox ì¶œë ¥                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         VS
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  System 3: VLG (GroundingDINO)                           â”‚
â”‚  â†’ ë¶ˆëŸ‰ ìœ í˜•ë³„ BBox ê²€ì¶œ                                 â”‚
â”‚  â†’ Query: "porosity", "resin overflow", "pollution"      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Web UI: 3ê°œ ì‹œìŠ¤í…œ ê²°ê³¼ ë¹„êµ ì‹œê°í™”                     â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€               â”‚
â”‚  [CT Grad-CAM] + [RGB Heatmap] = ì¢…í•© íŒì • ë·°            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ—‚ï¸ í´ë” êµ¬ì¡°

### í˜„ì¬ êµ¬í˜„ëœ êµ¬ì¡° (Phase 3)

```
battery-inspection/
â”œâ”€â”€ CLAUDE.md                               # Claude ê°œë°œ ê°€ì´ë“œ
â”œâ”€â”€ TASK.md                                 # ì‘ì—… í˜„í™© (ìš°ì„  ì°¸ì¡°!)
â”œâ”€â”€ README.md
â”‚
â”œâ”€â”€ data -> /home/ubuntu/battery-data       # ì‹¬ë³¼ë¦­ ë§í¬ (ì›ë³¸ ë°ì´í„°)
â”‚
â”œâ”€â”€ docs/                                   # ë¬¸ì„œ
â”‚   â”œâ”€â”€ implementation_structure.md         # ë³¸ ë¬¸ì„œ (ì „ì²´ ì„¤ê³„)
â”‚   â”œâ”€â”€ inspector_design.md                  # í†µí•© ê²€ì‚¬ ì„¤ê³„
â”‚   â”œâ”€â”€ MODEL_ARCHITECTURE.md               # ëª¨ë¸ ì•„í‚¤í…ì²˜
â”‚   â””â”€â”€ TENSORBOARD_GUIDE.md                # TensorBoard ì‚¬ìš© ê°€ì´ë“œ
â”‚
â”œâ”€â”€ models/                                 # â­ ëª¨ë¸ í•™ìŠµ/ì¶”ë¡ 
â”‚   â”œâ”€â”€ ct_cnn/                            # CT í†µí•© CNN (5í´ë˜ìŠ¤)
â”‚   â”‚   â”œâ”€â”€ train.py                       # í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸
â”‚   â”‚   â”œâ”€â”€ test.py                        # í‰ê°€ ìŠ¤í¬ë¦½íŠ¸
â”‚   â”‚   â”œâ”€â”€ model.py                       # ResNet18 ëª¨ë¸ ì •ì˜
â”‚   â”‚   â”œâ”€â”€ checkpoints/                   # ì²´í¬í¬ì¸íŠ¸ ì €ì¥
â”‚   â”‚   â”‚   â”œâ”€â”€ ct_unified_best_*.pt      # Best ëª¨ë¸
â”‚   â”‚   â”‚   â””â”€â”€ ct_unified_last_*.pt      # ìµœì‹  ëª¨ë¸
â”‚   â”‚   â””â”€â”€ logs/                          # TensorBoard ë¡œê·¸
â”‚   â”‚
â”‚   â”œâ”€â”€ rgb_ae/                            # RGB AutoEncoder (ì´ìƒíƒì§€)
â”‚   â”‚   â””â”€â”€ checkpoints/                   # ì²´í¬í¬ì¸íŠ¸ ì €ì¥
â”‚   â”‚
â”‚   â”œâ”€â”€ vlm/                               # âœ… VLM (Qwen2-VL) - êµ¬í˜„ ì™„ë£Œ
â”‚   â”‚   â”œâ”€â”€ inference.py                   # VLM ì¶”ë¡  ëª¨ë“ˆ
â”‚   â”‚   â””â”€â”€ prompts.py                     # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ (5í´ë˜ìŠ¤)
â”‚   â”‚
â”‚   â””â”€â”€ vlg/                               # âœ… VLG (GroundingDINO) - êµ¬í˜„ ì™„ë£Œ
â”‚       â”œâ”€â”€ inference.py                   # VLG ì¶”ë¡  ëª¨ë“ˆ
â”‚       â”œâ”€â”€ prompts.py                     # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ (5í´ë˜ìŠ¤ ë§¤í•‘)
â”‚       â””â”€â”€ weights/                       # ì‚¬ì „í•™ìŠµ ê°€ì¤‘ì¹˜
â”‚           â””â”€â”€ groundingdino_swint_ogc.pth  # swinT ê°€ì¤‘ì¹˜ (662MB)
â”‚
â”œâ”€â”€ webapp/                                # âœ… Streamlit ì›¹ì•± - êµ¬í˜„ ì™„ë£Œ
â”‚   â”œâ”€â”€ app.py                             # ë©”ì¸ ì•± (í˜ì´ì§€ ë¼ìš°íŒ…)
â”‚   â”œâ”€â”€ pages/                             # í˜ì´ì§€ ì»´í¬ë„ŒíŠ¸
â”‚   â”‚   â”œâ”€â”€ home.py                        # í™ˆ (ì´ë¯¸ì§€ ì—…ë¡œë“œ)
â”‚   â”‚   â”œâ”€â”€ processing.py                  # ë¶„ì„ ì§„í–‰ í˜ì´ì§€
â”‚   â”‚   â””â”€â”€ summary.py                     # 3-Way ë¹„êµ ê²°ê³¼ í˜ì´ì§€
â”‚   â””â”€â”€ utils/                             # ìœ í‹¸ë¦¬í‹°
â”‚       â”œâ”€â”€ session.py                     # ì„¸ì…˜ ìƒíƒœ ê´€ë¦¬
â”‚       â”œâ”€â”€ styles.py                      # CSS ìŠ¤íƒ€ì¼ (ë¼ì´íŠ¸ í…Œë§ˆ)
â”‚       â””â”€â”€ defect_info.py                 # ê²°í•¨ ì •ë³´ ë§¤í•‘ (5í´ë˜ìŠ¤)
â”‚
â”œâ”€â”€ scripts/                               # ìœ í‹¸ë¦¬í‹° ìŠ¤í¬ë¦½íŠ¸
â”‚   â”œâ”€â”€ create_splits_final.py             # ë°ì´í„° ë¶„í•  ìƒì„±
â”‚   â”œâ”€â”€ check_data_leakage.py              # Data Leakage ê²€ì¦
â”‚   â””â”€â”€ check_label_consistency.py         # ë¼ë²¨ ì¼ê´€ì„± ê²€ì¦
â”‚
â”œâ”€â”€ training/                              # â­ í•™ìŠµ ê´€ë ¨ ëª¨ë“ˆ
â”‚   â”œâ”€â”€ configs/                           # YAML ì„¤ì • íŒŒì¼
â”‚   â”‚   â”œâ”€â”€ cnn_ct_unified.yaml           # CT CNN í•™ìŠµ ì„¤ì •
â”‚   â”‚   â”œâ”€â”€ autoencoder_rgb.yaml          # RGB AE í•™ìŠµ ì„¤ì •
â”‚   â”‚   â”œâ”€â”€ inspector.yaml                 # í†µí•© ê²€ì‚¬ ì„¤ì •
â”‚   â”‚   â””â”€â”€ config_loader.py              # Config ë¡œë”
â”‚   â”‚
â”‚   â”œâ”€â”€ data/                             # ë°ì´í„° ì²˜ë¦¬
â”‚   â”‚   â”œâ”€â”€ dataset.py                    # BatteryDataset í´ë˜ìŠ¤
â”‚   â”‚   â”œâ”€â”€ dataloader.py                 # DataLoader íŒ©í† ë¦¬
â”‚   â”‚   â””â”€â”€ splits/                       # Train/Val/Test ë¶„í•  íŒŒì¼
â”‚   â”‚       â”œâ”€â”€ ct/                       # CT ë°ì´í„° ë¶„í• 
â”‚   â”‚       â”‚   â”œâ”€â”€ train.txt             # 138,316ê°œ
â”‚   â”‚       â”‚   â”œâ”€â”€ val.txt               # 26,662ê°œ
â”‚   â”‚       â”‚   â””â”€â”€ test.txt              # 36,424ê°œ
â”‚   â”‚       â””â”€â”€ rgb/                      # RGB ë°ì´í„° ë¶„í• 
â”‚   â”‚           â”œâ”€â”€ train.txt
â”‚   â”‚           â”œâ”€â”€ val.txt
â”‚   â”‚           â””â”€â”€ test.txt
â”‚   â”‚
â”‚   â”œâ”€â”€ evaluation/                       # í‰ê°€ ëª¨ë“ˆ
â”‚   â”‚   â””â”€â”€ metrics.py                    # ë©”íŠ¸ë¦­ ê³„ì‚°
â”‚   â”‚
â”‚   â””â”€â”€ visualization/                    # ì‹œê°í™”
â”‚       â””â”€â”€ tensorboard_logger.py         # TensorBoard ë¡œê±°
â”‚
â””â”€â”€ .envrc                                # direnv ì„¤ì •
```

### í–¥í›„ êµ¬í˜„ ì˜ˆì • êµ¬ì¡° (Phase 4~5)

```
battery-inspection/
â”œâ”€â”€ (í˜„ì¬ êµ¬ì¡°...)
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ inspector/                        # â³ Phase 4: í†µí•© ê²€ì‚¬ ì¶”ë¡ 
â”‚       â”œâ”€â”€ inference.py                 # CT CNN + RGB AE í†µí•© ê²€ì‚¬
â”‚       â””â”€â”€ gradcam.py                   # Grad-CAM ì‹œê°í™”
â”‚
â””â”€â”€ webapp/
    â””â”€â”€ pages/
        â””â”€â”€ processing.py                # â³ Phase 5: ì‹¤ì œ ëª¨ë¸ ì—°ë™
            # í˜„ì¬: ë”ë¯¸ ë°ì´í„°
            # ëª©í‘œ: VLM/VLG/Ensemble ì‹¤ì œ í˜¸ì¶œ
```

### âœ… êµ¬í˜„ ì™„ë£Œëœ í•­ëª© (ê¸°ì¡´ Phase 4~6)

| ê¸°ì¡´ ê³„íš | ìƒíƒœ | êµ¬í˜„ ìœ„ì¹˜ |
|-----------|------|-----------|
| VLM (Qwen2-VL) | âœ… ì™„ë£Œ | `models/vlm/inference.py` |
| VLG (GroundingDINO) | âœ… ì™„ë£Œ | `models/vlg/inference.py` |
| Streamlit UI | âœ… ì™„ë£Œ | `webapp/` |
| 5í´ë˜ìŠ¤ í†µì¼ | âœ… ì™„ë£Œ | `prompts.py`, `defect_info.py` |
| ê²°í•¨ ì •ë³´ ë§¤í•‘ | âœ… ì™„ë£Œ | `webapp/utils/defect_info.py` |

---

## ğŸ¤– VLM/VLG ëª¨ë¸ ìƒì„¸

### VLM (Vision-Language Model)

| í•­ëª© | ê°’ |
|------|-----|
| **ëª¨ë¸** | Qwen2-VL (HuggingFace) |
| **ì§€ì› í¬ê¸°** | 2B, 7B, 72B |
| **ê¸°ë³¸ê°’** | 7B (~16GB VRAM) |
| **ì¶œë ¥** | ìì—°ì–´ ì„¤ëª… + ë¶„ë¥˜ ê²°ê³¼ |
| **í”„ë¡¬í”„íŠ¸** | CT/RGB ë¶„ì„ìš© í•œêµ­ì–´ í”„ë¡¬í”„íŠ¸ |

```python
# ì‚¬ìš© ì˜ˆì‹œ
from models.vlm.inference import VLMInference
vlm = VLMInference(model_size='7b', device='cuda')
result = vlm.analyze_image('image.jpg', modality='ct')
```

### VLG (Vision-Language Grounding)

| í•­ëª© | ê°’ |
|------|-----|
| **ëª¨ë¸** | GroundingDINO |
| **ì§€ì› ë°±ë³¸** | swinT (662MB), swinB (1GB) |
| **ê¸°ë³¸ê°’** | swinT (~4GB VRAM) |
| **ì¶œë ¥** | ë°”ìš´ë”© ë°•ìŠ¤ + ë¼ë²¨ + ì‹ ë¢°ë„ |
| **ê°€ì¤‘ì¹˜ ê²½ë¡œ** | `models/vlg/weights/groundingdino_swint_ogc.pth` |

```python
# ì‚¬ìš© ì˜ˆì‹œ
from models.vlg.inference import VLGInference
vlg = VLGInference(model_type='swinT', device='cuda')
result = vlg.detect('image.jpg', modality='ct')
```

### 5í´ë˜ìŠ¤ í†µì¼ ì²´ê³„

| í´ë˜ìŠ¤ | ì„¤ëª… | ì‹¬ê°ë„ |
|--------|------|--------|
| `cell_normal` | ì •ìƒ ì…€ | SUCCESS |
| `cell_porosity` | ì…€ ë‚´ë¶€ ê¸°ê³µ ê²°í•¨ | CRITICAL |
| `module_normal` | ì •ìƒ ëª¨ë“ˆ | SUCCESS |
| `module_porosity` | ëª¨ë“ˆ ë‚´ë¶€ ê¸°ê³µ ê²°í•¨ | CRITICAL |
| `module_resin_overflow` | ë ˆì§„ ì˜¤ë²„í”Œë¡œìš° | WARNING |

---

## ğŸŒ Webapp êµ¬ì¡°

### í˜ì´ì§€ íë¦„

```
[Home] â†’ [Processing] â†’ [Summary]
  â”‚          â”‚             â”‚
  â”‚          â”‚             â””â”€â”€ 3-Way ë¹„êµ ê²°ê³¼
  â”‚          â”‚                 - Ensemble ìƒì„¸
  â”‚          â”‚                 - VLM ìƒì„¸
  â”‚          â”‚                 - VLG ìƒì„¸
  â”‚          â”‚                 - ìµœì¢… íŒì •
  â”‚          â”‚
  â”‚          â””â”€â”€ 3ê°œ ëª¨ë¸ ìˆœì°¨ ë¶„ì„
  â”‚              - Ensemble (CNN+AE)
  â”‚              - VLM (Qwen2-VL)
  â”‚              - VLG (GroundingDINO)
  â”‚
  â””â”€â”€ ì´ë¯¸ì§€ ì—…ë¡œë“œ ë˜ëŠ” Demo
```

### ì‹¤í–‰ ë°©ë²•

```bash
# Webapp ì‹¤í–‰
streamlit run webapp/app.py --server.port 8501

# ì ‘ì†
http://localhost:8501
```

---

## ğŸ¯ í•µì‹¬ ì„¤ê³„ ì›ì¹™

### 1. Backend-Frontend ë¶„ë¦¬

**Backend (FastAPI)**
- ëª¨ë¸ ì¶”ë¡ ë§Œ ë‹´ë‹¹
- RESTful APIë¡œ ê²°ê³¼ ì œê³µ
- ë…ë¦½ì ìœ¼ë¡œ ì‹¤í–‰ ë° í…ŒìŠ¤íŠ¸ ê°€ëŠ¥

**Frontend (Streamlit)**
- ì‚¬ìš©ì ì¸í„°ë™ì…˜
- API í˜¸ì¶œ ë° ê²°ê³¼ ì‹œê°í™”
- Backend ë…ë¦½ì  ê°œë°œ ê°€ëŠ¥

### 2. Training-Inference ë¶„ë¦¬

**Training í´ë”**
- ëª¨ë¸ í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸
- TensorBoard ë¡œê¹…
- í•œ ë²ˆ í•™ìŠµ í›„ ì²´í¬í¬ì¸íŠ¸ ì €ì¥

**Backend í´ë”**
- í•™ìŠµëœ ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
- ì¶”ë¡ ë§Œ ìˆ˜í–‰
- ë¹ ë¥¸ ì‘ë‹µ ì‹œê°„ ìµœì í™”

### 3. í†µí•© ê²€ì‚¬ í†µí•© ì‹¤í–‰

```python
# backend/app/core/pipeline.py
class InferencePipeline:
    """í†µí•© ê²€ì‚¬ ì‹œìŠ¤í…œ + VLM/VLG ë¹„êµ ì‹¤í–‰"""

    def __init__(self):
        # í†µí•© ê²€ì‚¬ ì‹œìŠ¤í…œ (CNN + AE + Grad-CAM)
        self.ensemble = EnsemblePredictor(config="training/configs/inspector.yaml")

        # ë¹„êµ ëŒ€ìƒ
        self.vlm = VLMInference()
        self.vlg = VLGInference()

    async def run_all(self, ct_image: str, rgb_image: str) -> dict:
        """
        í†µí•© ê²€ì‚¬ + VLM/VLG ë¹„êµ ì‹¤í–‰

        Args:
            ct_image: CT ì´ë¯¸ì§€ ê²½ë¡œ
            rgb_image: RGB ì´ë¯¸ì§€ ê²½ë¡œ

        Returns:
            {
                "ensemble": {...},  # CNN+AE+Grad-CAM í†µí•© ê²°ê³¼
                "vlm": {...},       # VLM ë…ë¦½ ê²°ê³¼
                "vlg": {...}        # VLG ë…ë¦½ ê²°ê³¼
            }
        """
        results = await asyncio.gather(
            self.ensemble.predict(ct_image, rgb_image),  # í†µí•© ê²€ì‚¬
            self.vlm.predict(rgb_image),                 # VLM
            self.vlg.predict(rgb_image),                 # VLG
            return_exceptions=True
        )

        return {
            "ensemble": results[0],
            "vlm": results[1],
            "vlg": results[2]
        }
```

---

## ğŸ“Š JSON Schema ì •ì˜

### Request Schema

```python
# backend/app/schemas/request.py
from pydantic import BaseModel
from typing import List, Optional

class InferenceRequest(BaseModel):
    """ë‹¨ì¼/ë°°ì¹˜ ì¶”ë¡  ìš”ì²­"""
    ct_image_path: str      # CT ì´ë¯¸ì§€ ê²½ë¡œ
    rgb_image_path: str     # RGB ì´ë¯¸ì§€ ê²½ë¡œ
    systems: Optional[List[str]] = ["ensemble", "vlm", "vlg"]  # ì‹¤í–‰í•  ì‹œìŠ¤í…œ ì„ íƒ

class InferenceRequestUpload(BaseModel):
    """íŒŒì¼ ì—…ë¡œë“œ ìš”ì²­"""
    ct_file: bytes
    rgb_file: bytes
```

### Response Schema

```python
# backend/app/schemas/response.py
from pydantic import BaseModel
from typing import List, Optional, Dict

class BoundingBox(BaseModel):
    x: float
    y: float
    w: float
    h: float

class EnsembleResult(BaseModel):
    """í†µí•© ê²€ì‚¬ ì‹œìŠ¤í…œ ê²°ê³¼ (CNN + AE + Grad-CAM)"""
    # ìµœì¢… íŒì •
    prediction: str  # "normal" or "defect"
    defect_type: Optional[str] = None  # "porosity", "resin_overflow", "pollution", "damaged"
    confidence: float  # 0~1

    # ê°œë³„ ëª¨ë¸ ê¸°ì—¬ë„
    cnn_prob: float  # CNN ì˜ˆì¸¡ í™•ë¥ 
    cnn_defect_type: Optional[str] = None  # CNNì´ ì˜ˆì¸¡í•œ ë¶ˆëŸ‰ ìœ í˜•
    ae_score: float  # AE ì´ìƒ ì ìˆ˜ (ì •ê·œí™”ë¨)

    # í†µí•© ê²€ì‚¬ ì •ë³´
    method: str  # "weighted_average", "voting", "rule_based"
    weights: Optional[Dict[str, float]] = None  # {"w_cnn": 0.6, "w_ae": 0.4}

    # Grad-CAM ìœ„ì¹˜ ì •ë³´
    gradcam_heatmap: Optional[str] = None  # íˆíŠ¸ë§µ ì´ë¯¸ì§€ ê²½ë¡œ
    gradcam_bbox: Optional[List[BoundingBox]] = None  # ì¶”ì¶œëœ BBox

class VLMResult(BaseModel):
    """VLM ê²°ê³¼"""
    prediction: str  # "normal" or "defect"
    defect_type: Optional[str] = None  # ë¶ˆëŸ‰ ìœ í˜• (VLMì´ ë¶„ì„í•œ)
    explanation: str  # ë¶ˆëŸ‰ ì›ì¸ ì„¤ëª…
    confidence: Optional[float] = None
    bbox: Optional[List[BoundingBox]] = None  # Grounding ìœ„ì¹˜ ì •ë³´

class VLGResult(BaseModel):
    """VLG ê²°ê³¼"""
    bboxes: List[BoundingBox]
    scores: List[float]
    defect_types: List[str]  # ê° bboxë³„ ë¶ˆëŸ‰ ìœ í˜• ("porosity", "pollution", etc.)

class InferenceResponse(BaseModel):
    """3ê°œ ì‹œìŠ¤í…œ ë¹„êµ ê²°ê³¼"""
    image_id: str

    # System 1: í†µí•© ê²€ì‚¬
    ensemble: Optional[EnsembleResult] = None

    # System 2: VLM
    vlm: Optional[VLMResult] = None

    # System 3: VLG
    vlg: Optional[VLGResult] = None

    class Config:
        schema_extra = {
            "example": {
                "image_id": "battery_001",
                "ensemble": {
                    "prediction": "defect",
                    "defect_type": "porosity",
                    "confidence": 0.78,
                    "cnn_prob": 0.85,
                    "cnn_defect_type": "porosity",
                    "ae_score": 0.72,
                    "method": "weighted_average",
                    "weights": {"w_cnn": 0.6, "w_ae": 0.4},
                    "gradcam_heatmap": "/runs/job_xxx/heatmap.jpg",
                    "gradcam_bbox": [{"x": 120, "y": 80, "w": 200, "h": 150}]
                },
                "vlm": {
                    "prediction": "defect",
                    "defect_type": "porosity",
                    "explanation": "ë°°í„°ë¦¬ ë‚´ë¶€ì— ê¸°ê³µ(porosity) ê²°í•¨ ë°œê²¬. ì „ê·¹ ì¸µ ì‚¬ì´ì— ê³µê·¹ì´ í˜•ì„±ë˜ì–´ ìˆìŒ.",
                    "confidence": 0.82,
                    "bbox": [{"x": 118, "y": 78, "w": 198, "h": 148}]
                },
                "vlg": {
                    "bboxes": [{"x": 115, "y": 85, "w": 205, "h": 145}],
                    "scores": [0.87],
                    "defect_types": ["porosity"]
                }
            }
        }
```

---

## ğŸŒ FastAPI ì—”ë“œí¬ì¸íŠ¸ ì„¤ê³„

```python
# backend/app/api/inference.py
from fastapi import APIRouter, UploadFile, File
from app.schemas.request import InferenceRequest
from app.schemas.response import InferenceResponse
from app.core.pipeline import InferencePipeline

router = APIRouter()
pipeline = InferencePipeline()

@router.post("/infer", response_model=InferenceResponse)
async def infer_single(request: InferenceRequest):
    """ë‹¨ì¼ ì´ë¯¸ì§€ ì¶”ë¡ """
    result = await pipeline.run_all(
        image_path=request.image_paths[0],
        modality=request.modality,
        models=request.models
    )
    return result

@router.post("/infer/batch", response_model=List[InferenceResponse])
async def infer_batch(request: InferenceRequest):
    """ë°°ì¹˜ ì´ë¯¸ì§€ ì¶”ë¡ """
    results = []
    for img_path in request.image_paths:
        result = await pipeline.run_all(img_path, request.modality, request.models)
        results.append(result)
    return results

@router.post("/upload")
async def upload_and_infer(files: List[UploadFile] = File(...), modality: str = "ct"):
    """íŒŒì¼ ì—…ë¡œë“œ + ì¶”ë¡ """
    # íŒŒì¼ ì €ì¥ í›„ ì¶”ë¡ 
    pass
```

```python
# backend/app/api/model_info.py
@router.get("/models")
async def get_model_info():
    """ëª¨ë¸ ì •ë³´ ì¡°íšŒ"""
    return {
        "cnn": {
            "name": "ResNet50",
            "pretrained": "ImageNet-1K",
            "available_for": ["ct"]
        },
        "autoencoder": {
            "name": "ConvAutoencoder",
            "available_for": ["rgb", "ct"]
        },
        "vlm": {
            "name": "Qwen3-VL-8B-Instruct",
            "available_for": ["rgb", "ct"]
        },
        "vlg": {
            "name": "GroundingDINO",
            "available_for": ["rgb", "ct"]
        }
    }
```

---

## ğŸ¨ Streamlit UI êµ¬ì¡°

```python
# frontend/app.py
import streamlit as st
from components.uploader import ImageUploader
from components.result_viewer import ResultViewer
from utils.api_client import APIClient

st.set_page_config(page_title="ë°°í„°ë¦¬ ë¶ˆëŸ‰ ê²€ì‚¬", layout="wide")

# ì‚¬ì´ë“œë°”: ëª¨ë‹¬ë¦¬í‹° ì„ íƒ
modality = st.sidebar.selectbox("ë°ì´í„° íƒ€ì…", ["RGB", "CT"])

# ë©”ì¸: ì´ë¯¸ì§€ ì—…ë¡œë“œ
uploader = ImageUploader()
uploaded_files = uploader.render()

if uploaded_files:
    # API í˜¸ì¶œ
    client = APIClient()
    results = client.infer(uploaded_files, modality.lower())

    # ê²°ê³¼ í‘œì‹œ
    viewer = ResultViewer()
    viewer.render(results)
```

```python
# frontend/components/result_viewer.py
import streamlit as st

class ResultViewer:
    def render(self, results):
        """ëª¨ë¸ë³„ ê²°ê³¼ íƒ­ í‘œì‹œ"""
        tab1, tab2, tab3, tab4 = st.tabs(["CNN", "AutoEncoder", "VLM", "VLG"])

        with tab1:
            self._render_cnn(results["cnn"])

        with tab2:
            self._render_ae(results["autoencoder"])

        with tab3:
            self._render_vlm(results["vlm"])

        with tab4:
            self._render_vlg(results["vlg"])

    def _render_cnn(self, cnn_result):
        st.subheader("CNN ë¶„ë¥˜ ê²°ê³¼")
        st.metric("íŒì •", cnn_result["pred"])
        st.progress(cnn_result["confidence"])

    def _render_ae(self, ae_result):
        st.subheader("AutoEncoder ì´ìƒ ê°ì§€")
        col1, col2 = st.columns(2)
        col1.metric("Anomaly Score", f"{ae_result['score']:.4f}")
        col2.metric("Threshold", f"{ae_result['threshold']:.4f}")

        # Score ë¶„í¬ íˆìŠ¤í† ê·¸ë¨ (ë°°ì¹˜ ì—…ë¡œë“œ ì‹œ)
        # ...

    def _render_vlm(self, vlm_result):
        st.subheader("VLM ì„¤ëª…")
        st.write(f"**íŒì •**: {vlm_result['judgement']}")
        st.write(f"**ì´ìœ **: {vlm_result['reason']}")

    def _render_vlg(self, vlg_result):
        st.subheader("VLG Bounding Box")
        # ì´ë¯¸ì§€ ìœ„ì— bbox ì˜¤ë²„ë ˆì´
        # ...
```

---

## ğŸ”„ ì‹¤í–‰ íë¦„

### 1. ëª¨ë¸ í•™ìŠµ (1íšŒ)

```bash
# 1. CT CNN í•™ìŠµ
cd training
python scripts/train_cnn_ct.py

# 2. RGB AutoEncoder í•™ìŠµ
python scripts/train_ae_rgb.py

# 3. CT AutoEncoder í•™ìŠµ
python scripts/train_ae_ct.py

# 4. TensorBoardë¡œ í•™ìŠµ ê³¼ì • í™•ì¸
tensorboard --logdir ../experiments/runs
```

### 2. Backend ì„œë²„ ì‹¤í–‰

```bash
cd backend
uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload
```

### 3. Frontend ì‹¤í–‰

```bash
cd frontend
streamlit run app.py
```

### 4. ì‚¬ìš©ì ì›Œí¬í”Œë¡œìš°

1. ì›¹ ë¸Œë¼ìš°ì €ì—ì„œ Streamlit ì ‘ì† (http://localhost:8501)
2. ëª¨ë‹¬ë¦¬í‹° ì„ íƒ (RGB/CT)
3. ì´ë¯¸ì§€ ì—…ë¡œë“œ (ë‹¨ì¼/ë°°ì¹˜)
4. ì‹¤í–‰í•  ëª¨ë¸ ì„ íƒ (CNN, AE, VLM, VLG)
5. ê²°ê³¼ íƒ­ë³„ë¡œ í™•ì¸
   - CNN: ë¶„ë¥˜ ê²°ê³¼ + Confidence
   - AE: Anomaly Score + Threshold
   - VLM: í…ìŠ¤íŠ¸ ì„¤ëª…
   - VLG: Bounding Box ì˜¤ë²„ë ˆì´
6. ë°°ì¹˜ ì—…ë¡œë“œ ì‹œ: Anomaly Score íˆìŠ¤í† ê·¸ë¨

---

## ğŸ“¦ ì£¼ìš” ì˜ì¡´ì„±

### Backend (backend/requirements.txt)

```txt
# FastAPI
fastapi>=0.104.0
uvicorn[standard]>=0.24.0
pydantic>=2.4.0
python-multipart>=0.0.6

# Deep Learning
torch>=2.0.0
torchvision>=0.15.0
timm>=0.9.0

# VLM/VLG
transformers>=4.35.0
# groundingdino (ì„¤ì¹˜ ë°©ë²• ë³„ë„)

# ì´ë¯¸ì§€ ì²˜ë¦¬
pillow>=10.0.0
opencv-python>=4.8.0

# ìœ í‹¸ë¦¬í‹°
python-dotenv>=1.0.0
```

### Frontend (frontend/requirements.txt)

```txt
streamlit>=1.28.0
requests>=2.31.0
pillow>=10.0.0
matplotlib>=3.7.0
plotly>=5.17.0  # ì¸í„°ë™í‹°ë¸Œ ê·¸ë˜í”„
```

### Training (training/requirements.txt)

```txt
torch>=2.0.0
torchvision>=0.15.0
timm>=0.9.0
tensorboard>=2.13.0
scikit-learn>=1.3.0
matplotlib>=3.7.0
seaborn>=0.12.0
tqdm>=4.65.0
```

---

## ğŸš€ êµ¬í˜„ ìš°ì„ ìˆœìœ„

### Phase 1: Backend ê¸°ë³¸ êµ¬ì¡° (2-3ì¼)
1. âœ… í´ë” êµ¬ì¡° ìƒì„±
2. âœ… Config íŒŒì¼ ì‘ì„±
3. âœ… Pydantic Schema ì •ì˜
4. âœ… FastAPI ê¸°ë³¸ ì—”ë“œí¬ì¸íŠ¸ êµ¬í˜„ (mock ì‘ë‹µ)
5. âœ… Health check API

### Phase 2: Training (3-4ì¼)
6. âœ… Dataset/DataLoader êµ¬í˜„
7. âœ… CNN (CT) í•™ìŠµ
8. âœ… AutoEncoder (RGB) í•™ìŠµ
9. âœ… Threshold ìë™ ê³„ì‚°
10. âœ… ì²´í¬í¬ì¸íŠ¸ ì €ì¥

### Phase 3: Backend ëª¨ë¸ ì—°ë™ + Grad-CAM (3-4ì¼)
11. âœ… CNN Predictor êµ¬í˜„
12. â­ Grad-CAM ëª¨ë“ˆ êµ¬í˜„ (pytorch-grad-cam ë¼ì´ë¸ŒëŸ¬ë¦¬)
13. â­ Heatmap â†’ BBox ì¶”ì¶œ í•¨ìˆ˜ êµ¬í˜„
14. â­ ì‹œê°í™” í•¨ìˆ˜ êµ¬í˜„ (heatmap overlay, bbox overlay)
15. â­ CNN Predictorì— Grad-CAM í†µí•©
16. âœ… AE Predictor êµ¬í˜„
17. âœ… InferencePipeline êµ¬í˜„
18. âœ… ì‹¤ì œ ì¶”ë¡  API ì—°ê²°

### Phase 4: Frontend (2-3ì¼)
19. âœ… Streamlit ê¸°ë³¸ UI
20. âœ… ì´ë¯¸ì§€ ì—…ë¡œë“œ ì»´í¬ë„ŒíŠ¸
21. âœ… API í´ë¼ì´ì–¸íŠ¸
22. âœ… ëª¨ë¸ë³„ ê²°ê³¼ íƒ­
23. â­ CNN Grad-CAM ì‹œê°í™” (heatmap + bbox overlay)
24. âœ… VLM/VLG Bounding Box ì˜¤ë²„ë ˆì´

### Phase 5: VLM/VLG (ì„ íƒì , 3-4ì¼)
25. â¸ï¸ VLM (Qwen3-VL) ë¡œì»¬ ì¶”ë¡ 
26. â¸ï¸ VLG (GroundingDINO) ì—°ë™
27. â¸ï¸ Frontendì— ê²°ê³¼ ì—°ë™

### Phase 6: ë°°ì¹˜ ì²˜ë¦¬ & ê³ ë„í™” (2-3ì¼)
28. â¸ï¸ ë°°ì¹˜ ì¶”ë¡  ìµœì í™”
29. â¸ï¸ Anomaly Score íˆìŠ¤í† ê·¸ë¨
30. â¸ï¸ ê²°ê³¼ ì €ì¥/ë¡œë“œ ê¸°ëŠ¥

---

## ğŸ¯ í•µì‹¬ ì°¨ë³„ì 

### 1. Web ê¸°ë°˜ ì‹¤ì‹œê°„ ë¹„êµ
- TensorBoard: í•™ìŠµ ê³¼ì •ë§Œ
- Streamlit: ì¶”ë¡  ê²°ê³¼ ì‹¤ì‹œê°„ ë¹„êµ

### 2. ì‚¬ìš©ì ì¹œí™”ì 
- CLI ëŒ€ì‹  ì›¹ UI
- ì´ë¯¸ì§€ ì—…ë¡œë“œë§Œìœ¼ë¡œ ëª¨ë“  ëª¨ë¸ ê²°ê³¼ í™•ì¸

### 3. í™•ì¥ ê°€ëŠ¥í•œ ì•„í‚¤í…ì²˜
- Backend-Frontend ë¶„ë¦¬
- Training-Inference ë¶„ë¦¬
- ìƒˆ ëª¨ë¸ ì¶”ê°€ ìš©ì´

### 4. ê²°ì •ì (Deterministic) íŒŒì´í”„ë¼ì¸
- ëª¨ë“  ëª¨ë¸ ë…ë¦½ ì‹¤í–‰
- ì¬í˜„ ê°€ëŠ¥í•œ ê²°ê³¼

---

## ğŸ“Š TensorBoard vs Web UI ì—­í•  ë¶„ë¦¬

### í•µì‹¬ ì›ì¹™
> **"í•™ìŠµ ê³¼ì •ì€ TensorBoardë¡œ, ìµœì¢… ê²°ê³¼ëŠ” ë¡œê·¸ ê¸°ë°˜ Web UIë¡œ ë³¸ë‹¤."**

- TensorBoard â‰  ì„œë¹„ìŠ¤ UI
- Web UI â‰  í•™ìŠµ ëª¨ë‹ˆí„°ë§ ë„êµ¬
- **ë‘ ì‹œìŠ¤í…œì€ ê°™ì€ ë¡œê·¸ë¥¼ ê³µìœ í•˜ì§€ ì•ŠëŠ”ë‹¤**

### ì—­í•  ë¶„ë‹´í‘œ

| í•­ëª© | TensorBoard | Web UI |
|------|-------------|--------|
| **í•™ìŠµ ëª¨ë‹ˆí„°ë§** | â­• ì£¼ ìš©ë„ | âŒ |
| **ì‹¤í—˜ ë¹„êµ** | â­• í•™ìŠµ ê³¼ì • ë¹„êµ | â­• ìµœì¢… ê²°ê³¼ ë¹„êµ |
| **ì´ë¯¸ì§€ë³„ ê²°ê³¼** | âŒ | â­• ì£¼ ìš©ë„ |
| **ì‚¬ìš©ì ì…ë ¥** | âŒ | â­• ì´ë¯¸ì§€ ì—…ë¡œë“œ |
| **ì„œë¹„ìŠ¤ í™•ì¥** | âŒ | â­• ë°°ì¹˜ ì²˜ë¦¬, API |

### TensorBoard ê¸°ë¡ ëŒ€ìƒ (í•™ìŠµìš©)

```python
# training/visualization/tensorboard_logger.py
class TensorBoardLogger:
    def log_training_metrics(self, epoch):
        """í•™ìŠµ ê³¼ì • ëª¨ë‹ˆí„°ë§"""
        self.writer.add_scalar('train/loss', train_loss, epoch)
        self.writer.add_scalar('val/loss', val_loss, epoch)
        self.writer.add_scalar('val/f1', val_f1, epoch)
        self.writer.add_scalar('lr', current_lr, epoch)

        # AutoEncoder: ì¬êµ¬ì„± ì´ë¯¸ì§€
        if epoch % 5 == 0:
            self.writer.add_image('reconstruction', recon_img, epoch)

        # ì¬êµ¬ì„± ì˜¤ë¥˜ ë¶„í¬ (Threshold ê²°ì •ìš©)
        self.writer.add_histogram('recon_error', errors, epoch)
```

**ê¸°ë¡ ëª©ì **:
- ìˆ˜ë ´ ì—¬ë¶€ í™•ì¸
- ê³¼ì í•© íŒë‹¨
- ì‹¤í—˜ ê°„ ë¹„êµ
- Threshold ê²°ì • (íˆìŠ¤í† ê·¸ë¨)

### Web UIê°€ ì½ëŠ” ë°ì´í„° (ì¶”ë¡  ê²°ê³¼ìš©)

| íŒŒì¼ | ê²½ë¡œ | ìš©ë„ |
|------|------|------|
| `result.json` | `experiments/results/job_xxx/` | ì´ë¯¸ì§€ë³„ ëª¨ë¸ ê²°ê³¼ |
| `summary.csv` | `experiments/results/job_xxx/` | Job ë‹¨ìœ„ metric ìš”ì•½ |
| `images/` | `experiments/results/job_xxx/images/` | bbox overlay, ì‹œê°í™” |

**result.json ì˜ˆì‹œ**:
```json
{
  "job_id": "job_20250101_001",
  "timestamp": "2025-01-01T10:30:00",
  "total_images": 50,
  "images": [
    {
      "image_id": "img_001.jpg",
      "cnn": {
        "pred": "defect",
        "confidence": 0.92
      },
      "autoencoder": {
        "score": 0.034,
        "threshold": 0.028,
        "is_anomaly": true
      },
      "vlm": {
        "judgement": "defect",
        "reason": "í‘œë©´ í¬ë™ ë°œê²¬"
      },
      "vlg": {
        "bboxes": [{"x": 120, "y": 30, "w": 240, "h": 160}],
        "scores": [0.87]
      }
    }
  ]
}
```

**summary.csv ì˜ˆì‹œ**:
```csv
job_id,total_images,defect_count,normal_count,avg_confidence,processing_time
job_20250101_001,50,12,38,0.89,45.2
```

### ì‹¤í—˜(run) ì´ë¦„ ê·œì¹™

**TensorBoard run ì´ë¦„ í˜•ì‹**:
```text
<model>_<key_param>_<value>_<key_param>_<value>
```

**ì˜ˆì‹œ**:
- `resnet18_lr1e-4_bs32` - CNN ì‹¤í—˜
- `resnet50_lr5e-5_bs16_wd1e-4` - CNN ì‹¤í—˜ (weight decay ì¶”ê°€)
- `ae_rgb_k2.5` - RGB AutoEncoder (k=2.5)
- `ae_ct_k2.0_latent128` - CT AutoEncoder (k=2.0, latent_dim=128)

**ì¥ì **:
- Run ì´ë¦„ë§Œ ë´ë„ ì‹¤í—˜ ì¡°ê±´ íŒŒì•… ê°€ëŠ¥
- TensorBoardì—ì„œ ì‹¤í—˜ ë¹„êµ ì‹œ ì§ê´€ì 

---

## ğŸ”„ ë¹„ë™ê¸° Job ì²˜ë¦¬ íë¦„ (run_id ê¸°ë°˜)

### í•µì‹¬ ì›ì¹™
> **"ì—…ë¡œë“œ â†’ ì²˜ë¦¬ â†’ ê²°ê³¼ ë³´ê¸°" ì™„ì „ ë¹„ë™ê¸° êµ¬ì¡°**

- ì—…ë¡œë“œì™€ ì²˜ë¦¬ ë¶„ë¦¬ â†’ ì‚¬ìš©ì ëŒ€ê¸° ì‹œê°„ âŒ
- ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì¶”ë¡  ìˆ˜í–‰
- ìƒíƒœ ì¡°íšŒë¡œ ì§„í–‰ ìƒí™© í™•ì¸
- **DB ì—†ì´ íŒŒì¼ ê¸°ë°˜ìœ¼ë¡œ ê°€ëŠ¥**

### ì „ì²´ íë¦„

```text
[Frontend] ì´ë¯¸ì§€ ì—…ë¡œë“œ
   â†“
[Backend] POST /upload
   â†“
run_id ìƒì„± (timestamp)
run_id = datetime.now().strftime('%Y%m%d_%H%M%S')
   â†“
experiments/runs/{run_id}/ ìƒì„±
   â”œâ”€ status.json (pending)
   â””â”€ input_images/ (ì´ë¯¸ì§€ ì €ì¥)
   â†“
ì¦‰ì‹œ run_id ë°˜í™˜ â†’ Frontend
   â†“
[Backend] BackgroundTasksë¡œ ì¶”ë¡  ì‹¤í–‰
   â”œâ”€ status.json â†’ "processing" ì—…ë°ì´íŠ¸
   â”œâ”€ CNN, AE, VLM, VLG ë³‘ë ¬ ì‹¤í–‰
   â”œâ”€ results/ ì— ëª¨ë¸ë³„ ê²°ê³¼ ì €ì¥
   â”œâ”€ summary.json ìƒì„±
   â””â”€ status.json â†’ "completed" ì—…ë°ì´íŠ¸
   â†“
[Frontend] Pollingìœ¼ë¡œ ìƒíƒœ í™•ì¸
GET /jobs/{run_id}/status (2ì´ˆë§ˆë‹¤)
   â†“
status = "completed" ê°ì§€
   â†“
[Frontend] ê²°ê³¼ ì¡°íšŒ
GET /jobs/{run_id}/results
   â†“
ì‹œê°í™” (ëª¨ë¸ë³„ íƒ­, ì´ë¯¸ì§€ë³„ ê²°ê³¼)
```

### Job ìƒíƒœ ê´€ë¦¬ (status.json)

**íŒŒì¼ ê²½ë¡œ**: `experiments/runs/{run_id}/status.json`

```json
{
  "run_id": "20250101_143210",
  "status": "processing",
  "created_at": "2025-01-01T14:32:10",
  "updated_at": "2025-01-01T14:32:15",
  "total_images": 10,
  "processed_images": 3,
  "progress_percent": 30,
  "error_message": null
}
```

**ìƒíƒœ ê°’**:
- `pending`: ì—…ë¡œë“œ ì™„ë£Œ, ì²˜ë¦¬ ëŒ€ê¸°
- `processing`: ì¶”ë¡  ì§„í–‰ ì¤‘
- `completed`: ëª¨ë“  ì²˜ë¦¬ ì™„ë£Œ
- `failed`: ì—ëŸ¬ ë°œìƒ

### Backend API ì—”ë“œí¬ì¸íŠ¸

```python
# backend/app/api/jobs.py
from fastapi import APIRouter, UploadFile, File, BackgroundTasks
from typing import List
import json
from datetime import datetime
from pathlib import Path

router = APIRouter(prefix="/jobs", tags=["jobs"])

@router.post("/upload")
async def upload_images(
    files: List[UploadFile] = File(...),
    modality: str = "ct",
    background_tasks: BackgroundTasks = None
):
    """
    ì´ë¯¸ì§€ ì—…ë¡œë“œ + ë¹„ë™ê¸° ì²˜ë¦¬ ì‹œì‘
    - run_id ì¦‰ì‹œ ë°˜í™˜
    - ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì¶”ë¡  ì‹¤í–‰
    """
    # 1. run_id ìƒì„±
    run_id = datetime.now().strftime('%Y%m%d_%H%M%S')
    run_dir = Path(f"experiments/runs/{run_id}")
    run_dir.mkdir(parents=True, exist_ok=True)

    # 2. ì´ë¯¸ì§€ ì €ì¥
    input_dir = run_dir / "input_images"
    input_dir.mkdir(exist_ok=True)

    image_paths = []
    for file in files:
        file_path = input_dir / file.filename
        with open(file_path, "wb") as f:
            f.write(await file.read())
        image_paths.append(str(file_path))

    # 3. ì´ˆê¸° ìƒíƒœ ì €ì¥
    status_data = {
        "run_id": run_id,
        "status": "pending",
        "created_at": datetime.now().isoformat(),
        "updated_at": datetime.now().isoformat(),
        "total_images": len(files),
        "processed_images": 0,
        "progress_percent": 0,
        "error_message": None
    }

    with open(run_dir / "status.json", "w") as f:
        json.dump(status_data, f, indent=2)

    # 4. ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ë“±ë¡
    background_tasks.add_task(
        process_inference,
        run_id=run_id,
        image_paths=image_paths,
        modality=modality
    )

    # 5. ì¦‰ì‹œ run_id ë°˜í™˜
    return {
        "run_id": run_id,
        "status": "pending",
        "message": "ì¶”ë¡ ì´ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì§„í–‰ë©ë‹ˆë‹¤."
    }


@router.get("/{run_id}/status")
async def get_job_status(run_id: str):
    """Job ìƒíƒœ ì¡°íšŒ (Frontend pollingìš©)"""
    status_path = Path(f"experiments/runs/{run_id}/status.json")

    if not status_path.exists():
        return {"error": "Run not found"}, 404

    with open(status_path) as f:
        status = json.load(f)

    return status


@router.get("/{run_id}/results")
async def get_job_results(run_id: str):
    """ì™„ë£Œëœ Jobì˜ ê²°ê³¼ ì¡°íšŒ"""
    run_dir = Path(f"experiments/runs/{run_id}")

    # 1. ìƒíƒœ í™•ì¸
    with open(run_dir / "status.json") as f:
        status = json.load(f)

    if status["status"] != "completed":
        return {
            "error": f"Job not completed yet. Current status: {status['status']}"
        }, 400

    # 2. summary.json ë¡œë“œ
    with open(run_dir / "summary.json") as f:
        summary = json.load(f)

    # 3. ëª¨ë¸ë³„ ê²°ê³¼ ë¡œë“œ (ì„ íƒì )
    results_dir = run_dir / "results"
    model_results = {}

    for result_file in results_dir.glob("*_result.json"):
        model_name = result_file.stem.replace("_result", "")
        with open(result_file) as f:
            model_results[model_name] = json.load(f)

    return {
        "run_id": run_id,
        "status": status,
        "summary": summary,
        "results": model_results
    }


async def process_inference(run_id: str, image_paths: List[str], modality: str):
    """
    ë°±ê·¸ë¼ìš´ë“œ ì¶”ë¡  ì‘ì—…
    - ìƒíƒœ ì—…ë°ì´íŠ¸
    - ëª¨ë¸ë³„ ì¶”ë¡ 
    - ê²°ê³¼ ì €ì¥
    """
    run_dir = Path(f"experiments/runs/{run_id}")

    try:
        # 1. ìƒíƒœ â†’ processing
        update_status(run_id, "processing", processed=0)

        # 2. ëª¨ë¸ ë¡œë“œ
        pipeline = InferencePipeline(modality=modality)

        # 3. ì´ë¯¸ì§€ë³„ ì¶”ë¡ 
        all_results = []
        for idx, img_path in enumerate(image_paths):
            result = await pipeline.run_all(img_path, modality)
            all_results.append(result)

            # ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸
            progress = int((idx + 1) / len(image_paths) * 100)
            update_status(run_id, "processing", processed=idx+1, progress=progress)

        # 4. ëª¨ë¸ë³„ ê²°ê³¼ ì €ì¥
        results_dir = run_dir / "results"
        results_dir.mkdir(exist_ok=True)

        # CNN ê²°ê³¼
        cnn_results = [r.cnn for r in all_results if r.cnn]
        with open(results_dir / "cnn_result.json", "w") as f:
            json.dump([r.dict() for r in cnn_results], f, indent=2)

        # AE ê²°ê³¼
        ae_results = [r.autoencoder for r in all_results if r.autoencoder]
        with open(results_dir / "ae_result.json", "w") as f:
            json.dump([r.dict() for r in ae_results], f, indent=2)

        # 5. summary.json ìƒì„±
        defect_count = sum(1 for r in all_results if r.cnn and r.cnn.pred == "defect")
        summary = {
            "run_id": run_id,
            "total_images": len(image_paths),
            "defect_count": defect_count,
            "normal_count": len(image_paths) - defect_count,
            "completed_at": datetime.now().isoformat()
        }

        with open(run_dir / "summary.json", "w") as f:
            json.dump(summary, f, indent=2)

        # 6. ìƒíƒœ â†’ completed
        update_status(run_id, "completed", processed=len(image_paths), progress=100)

    except Exception as e:
        # ì—ëŸ¬ ì‹œ ìƒíƒœ ì—…ë°ì´íŠ¸
        update_status(run_id, "failed", error=str(e))


def update_status(run_id: str, status: str, processed: int = None, progress: int = None, error: str = None):
    """ìƒíƒœ ì—…ë°ì´íŠ¸ í—¬í¼"""
    status_path = Path(f"experiments/runs/{run_id}/status.json")

    with open(status_path) as f:
        data = json.load(f)

    data["status"] = status
    data["updated_at"] = datetime.now().isoformat()

    if processed is not None:
        data["processed_images"] = processed
    if progress is not None:
        data["progress_percent"] = progress
    if error is not None:
        data["error_message"] = error

    with open(status_path, "w") as f:
        json.dump(data, f, indent=2)
```

### Frontend Polling ë¡œì§ (Streamlit)

```python
# frontend/app.py
import streamlit as st
import requests
import time
from pathlib import Path

API_BASE = "http://localhost:8000"

st.set_page_config(page_title="ë°°í„°ë¦¬ ë¶ˆëŸ‰ ê²€ì‚¬", layout="wide")

# ì‚¬ì´ë“œë°”: ì´ì „ run ì„ íƒ
st.sidebar.subheader("ì´ì „ ê²°ê³¼ ë¶ˆëŸ¬ì˜¤ê¸°")
run_dirs = list(Path("experiments/runs").glob("*"))
run_ids = [d.name for d in sorted(run_dirs, reverse=True)]

selected_run = st.sidebar.selectbox("Run ì„ íƒ", ["ìƒˆë¡œìš´ ì¶”ë¡ "] + run_ids)

if selected_run == "ìƒˆë¡œìš´ ì¶”ë¡ ":
    # 1. ì´ë¯¸ì§€ ì—…ë¡œë“œ
    st.header("ì´ë¯¸ì§€ ì—…ë¡œë“œ")
    uploaded_files = st.file_uploader("ì´ë¯¸ì§€ ì„ íƒ", accept_multiple_files=True, type=["jpg", "jpeg", "png"])
    modality = st.selectbox("ë°ì´í„° íƒ€ì…", ["RGB", "CT"])

    if uploaded_files and st.button("ì¶”ë¡  ì‹œì‘"):
        # 2. Backendì— ì—…ë¡œë“œ
        files = [("files", (f.name, f, "image/jpeg")) for f in uploaded_files]
        response = requests.post(
            f"{API_BASE}/jobs/upload",
            files=files,
            params={"modality": modality.lower()}
        )

        if response.status_code == 200:
            data = response.json()
            run_id = data["run_id"]

            st.success(f"âœ… Run ID: {run_id}")
            st.info("ğŸ“Š ì¶”ë¡ ì´ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤...")

            # 3. Pollingìœ¼ë¡œ ìƒíƒœ í™•ì¸
            progress_bar = st.progress(0)
            status_text = st.empty()

            while True:
                # ìƒíƒœ ì¡°íšŒ
                status_response = requests.get(f"{API_BASE}/jobs/{run_id}/status")
                status_data = status_response.json()

                # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
                progress = status_data.get("progress_percent", 0)
                progress_bar.progress(progress / 100)
                status_text.text(f"ì²˜ë¦¬ ì¤‘... {status_data['processed_images']}/{status_data['total_images']} ({progress}%)")

                # ì™„ë£Œ í™•ì¸
                if status_data["status"] == "completed":
                    st.success("âœ… ì¶”ë¡  ì™„ë£Œ!")
                    break
                elif status_data["status"] == "failed":
                    st.error(f"âŒ ì—ëŸ¬ ë°œìƒ: {status_data.get('error_message')}")
                    break

                # 2ì´ˆ ëŒ€ê¸°
                time.sleep(2)

            # 4. ê²°ê³¼ ë¡œë“œ
            if status_data["status"] == "completed":
                results_response = requests.get(f"{API_BASE}/jobs/{run_id}/results")
                results = results_response.json()

                # ê²°ê³¼ í‘œì‹œ
                display_results(results)

else:
    # ê¸°ì¡´ ê²°ê³¼ ë¡œë“œ
    st.header(f"Run: {selected_run}")

    # APIë¥¼ í†µí•´ ê²°ê³¼ ì¡°íšŒ
    results_response = requests.get(f"{API_BASE}/jobs/{selected_run}/results")

    if results_response.status_code == 200:
        results = results_response.json()
        display_results(results)
    else:
        st.error("ê²°ê³¼ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")


def display_results(results):
    """ê²°ê³¼ ì‹œê°í™”"""
    st.subheader("ğŸ“Š ìš”ì•½")

    col1, col2, col3 = st.columns(3)
    summary = results["summary"]
    col1.metric("ì „ì²´ ì´ë¯¸ì§€", summary["total_images"])
    col2.metric("ë¶ˆëŸ‰", summary["defect_count"])
    col3.metric("ì •ìƒ", summary["normal_count"])

    # ëª¨ë¸ë³„ ê²°ê³¼ íƒ­
    tabs = st.tabs(["CNN", "AutoEncoder", "VLM", "VLG"])

    with tabs[0]:
        st.subheader("CNN ë¶„ë¥˜ ê²°ê³¼")
        # CNN ê²°ê³¼ í‘œì‹œ...

    with tabs[1]:
        st.subheader("AutoEncoder ì´ìƒ ê°ì§€")
        # AE ê²°ê³¼ í‘œì‹œ...

    # ...
```

---

## ğŸ”§ ëª¨ë¸ë³„ Inference ë¡œì§ (Threshold Config ë¡œë”©)

### í•µì‹¬ ì›ì¹™
> **"Inferenceì—ì„œ Thresholdë¥¼ ì§ì ‘ ì“°ë©´ ì•ˆ ë˜ê³  ë°˜ë“œì‹œ config íŒŒì¼ì—ì„œ ë¡œë“œ"**

- í•˜ë“œì½”ë”© âŒ
- í•™ìŠµ ì‹œ ì €ì¥ëœ `threshold.json` ë¡œë“œ âœ…
- ì¬í˜„ ê°€ëŠ¥ì„± í™•ë³´

### AutoEncoder Predictor (Threshold ë¡œë”©)

```python
# backend/app/models/autoencoder/predictor.py
import torch
import json
from pathlib import Path
from typing import Dict

class AEPredictor:
    """AutoEncoder ì¶”ë¡ ê¸° - Threshold Config ë¡œë”©"""

    def __init__(self, modality: str):
        """
        Args:
            modality: "rgb" or "ct"
        """
        self.modality = modality
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

        # 1. ëª¨ë¸ ë¡œë“œ
        checkpoint_path = Path(f"experiments/checkpoints/autoencoder/ae_{modality}.pt")
        self.model = self._load_model(checkpoint_path)
        self.model.eval()

        # 2. â­ Threshold ë¡œë“œ (config íŒŒì¼ì—ì„œ!)
        threshold_path = Path(f"experiments/checkpoints/autoencoder/ae_{modality}_threshold.json")
        self.threshold_config = self._load_threshold(threshold_path)

        print(f"âœ… AE ({modality}) ë¡œë“œ ì™„ë£Œ")
        print(f"  - Threshold: {self.threshold_config['threshold']:.4f}")
        print(f"  - Method: {self.threshold_config['method']}")

    def _load_model(self, path: Path):
        """ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ"""
        checkpoint = torch.load(path, map_location=self.device)
        model = AutoEncoderModel()  # ëª¨ë¸ ì•„í‚¤í…ì²˜ ì •ì˜
        model.load_state_dict(checkpoint['model_state_dict'])
        model.to(self.device)
        return model

    def _load_threshold(self, path: Path) -> Dict:
        """â­ Threshold Config ë¡œë“œ (í•„ìˆ˜)"""
        if not path.exists():
            raise FileNotFoundError(
                f"Threshold íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {path}\n"
                f"í•™ìŠµ í›„ ë°˜ë“œì‹œ threshold.jsonì„ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤."
            )

        with open(path) as f:
            config = json.load(f)

        # í•„ìˆ˜ í•„ë“œ ê²€ì¦
        required_fields = ["threshold", "method", "mean_error", "std_error"]
        for field in required_fields:
            if field not in config:
                raise ValueError(f"Threshold configì— {field} í•„ë“œê°€ ì—†ìŠµë‹ˆë‹¤.")

        return config

    async def predict(self, image_path: str) -> Dict:
        """ì¶”ë¡  ì‹¤í–‰"""
        # 1. ì´ë¯¸ì§€ ë¡œë“œ + ì „ì²˜ë¦¬
        image_tensor = self._preprocess(image_path)

        # 2. ì¬êµ¬ì„±
        with torch.no_grad():
            reconstructed = self.model(image_tensor)

        # 3. ì¬êµ¬ì„± ì˜¤ë¥˜ ê³„ì‚°
        error = torch.nn.functional.mse_loss(image_tensor, reconstructed).item()

        # 4. â­ Thresholdì™€ ë¹„êµ (configì—ì„œ ë¡œë“œí•œ ê°’ ì‚¬ìš©!)
        threshold = self.threshold_config["threshold"]
        is_anomaly = error > threshold

        return {
            "score": float(error),
            "threshold": float(threshold),
            "is_anomaly": bool(is_anomaly),
            "method": self.threshold_config["method"],  # ì •ë³´ ì œê³µ
            "k": self.threshold_config.get("k")  # mean_std ë°©ì‹ì¼ ê²½ìš°
        }
```

### CNN Predictor (Grad-CAM í†µí•©)

```python
# backend/app/models/cnn/predictor.py
import torch
from pathlib import Path
from typing import Dict, Optional
from .gradcam import GradCAMGenerator
from .bbox_extractor import extract_bboxes_from_heatmap
from .visualizer import visualize_gradcam

class CNNPredictor:
    """CNN ì¶”ë¡ ê¸° + Grad-CAM ìœ„ì¹˜ ì •ë³´"""

    def __init__(self, modality: str = "ct", enable_gradcam: bool = True):
        """
        CNNì€ CT ë°ì´í„°ë§Œ ì§€ì›

        Args:
            modality: "ct"ë§Œ ì§€ì›
            enable_gradcam: Grad-CAM í™œì„±í™” ì—¬ë¶€
        """
        if modality != "ct":
            raise ValueError("CNNì€ CT ë°ì´í„°ë§Œ ì§€ì›í•©ë‹ˆë‹¤.")

        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.enable_gradcam = enable_gradcam

        # 1. ëª¨ë¸ ë¡œë“œ
        checkpoint_path = Path("experiments/checkpoints/cnn/resnet18_best.pt")
        self.model = self._load_model(checkpoint_path)
        self.model.eval()

        # 2. â­ Grad-CAM ì´ˆê¸°í™”
        if self.enable_gradcam:
            self.gradcam_generator = GradCAMGenerator(
                model=self.model,
                target_layer=self.model.layer4[-1]  # ResNet ë§ˆì§€ë§‰ Conv ë ˆì´ì–´
            )

        print("âœ… CNN (CT) ë¡œë“œ ì™„ë£Œ")
        if self.enable_gradcam:
            print("  - Grad-CAM í™œì„±í™”")

    def _load_model(self, path: Path):
        """ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ"""
        checkpoint = torch.load(path, map_location=self.device)
        model = ResNet18(num_classes=1)  # BCEWithLogitsLoss
        model.load_state_dict(checkpoint['model_state_dict'])
        model.to(self.device)
        return model

    async def predict(self, image_path: str, save_visualization: bool = True) -> Dict:
        """
        ì¶”ë¡  ì‹¤í–‰ + Grad-CAM ìœ„ì¹˜ ì •ë³´

        Args:
            image_path: ì´ë¯¸ì§€ ê²½ë¡œ
            save_visualization: ì‹œê°í™” ì´ë¯¸ì§€ ì €ì¥ ì—¬ë¶€

        Returns:
            {
                "pred": "defect" or "normal",
                "confidence": 0.95,
                "bboxes": [{"x": 120, "y": 340, "w": 50, "h": 80, "score": 0.92}],
                "visualization": {"heatmap": "path/to/heatmap.jpg", ...}
            }
        """
        # 1. ì´ë¯¸ì§€ ì „ì²˜ë¦¬
        image_tensor = self._preprocess(image_path)
        original_image = self._load_original_image(image_path)

        # 2. ì¶”ë¡ 
        with torch.no_grad():
            logit = self.model(image_tensor)
            prob = torch.sigmoid(logit)
            confidence = prob.item()

        # 3. ê²°ê³¼ íŒì •
        pred_label = "defect" if confidence > 0.4 else "normal"

        result = {
            "pred": pred_label,
            "confidence": float(confidence)
        }

        # 4. â­ Grad-CAM ìƒì„± (ë¶ˆëŸ‰ì¼ ê²½ìš°ì—ë§Œ)
        if self.enable_gradcam and pred_label == "defect":
            # Heatmap ìƒì„±
            heatmap = self.gradcam_generator.generate(
                image_tensor,
                target_class=1  # defect class
            )

            # BBox ì¶”ì¶œ
            bboxes = extract_bboxes_from_heatmap(
                heatmap=heatmap,
                threshold=0.5,  # Heatmap threshold
                min_area=100
            )

            result["bboxes"] = bboxes

            # 5. ì‹œê°í™” ì €ì¥ (ì„ íƒì )
            if save_visualization and bboxes:
                vis_paths = visualize_gradcam(
                    original_image=original_image,
                    heatmap=heatmap,
                    bboxes=bboxes,
                    image_name=Path(image_path).stem,
                    save_dir=Path("experiments/runs/current/visualizations")
                )
                result["visualization"] = vis_paths

        return result
```

### InferencePipeline (ëª¨ë¸ ë…ë¦½ ì‹¤í–‰)

```python
# backend/app/core/pipeline.py
import asyncio
from app.models.cnn.predictor import CNNPredictor
from app.models.autoencoder.predictor import AEPredictor
from app.models.vlm.inference import VLMInference
from app.models.vlg.inference import VLGInference

class InferencePipeline:
    """ëª¨ë¸ë³„ ë…ë¦½ ì‹¤í–‰ íŒŒì´í”„ë¼ì¸"""

    def __init__(self, modality: str):
        """
        Args:
            modality: "rgb" or "ct"
        """
        self.modality = modality

        # â­ ëª¨ë¸ ì´ˆê¸°í™” (ê°ì ë…ë¦½ì ìœ¼ë¡œ ì„¤ì • ë¡œë“œ)
        if modality == "ct":
            self.cnn = CNNPredictor(modality="ct")
        else:
            self.cnn = None  # RGBëŠ” CNN ë¯¸ì§€ì›

        self.ae = AEPredictor(modality=modality)  # Threshold ìë™ ë¡œë“œ
        self.vlm = VLMInference()  # ì„ íƒì 
        self.vlg = VLGInference()  # ì„ íƒì 

    async def run_all(self, image_path: str, modality: str):
        """ëª¨ë“  ëª¨ë¸ ë³‘ë ¬ ì‹¤í–‰"""
        tasks = []

        # 1. CNN (CTë§Œ)
        if self.cnn is not None:
            tasks.append(self.cnn.predict(image_path))
        else:
            tasks.append(self._return_none())  # í”Œë ˆì´ìŠ¤í™€ë”

        # 2. AutoEncoder (í•­ìƒ)
        tasks.append(self.ae.predict(image_path))

        # 3. VLM/VLG (ì„ íƒì )
        if self.vlm:
            tasks.append(self.vlm.predict(image_path))
        else:
            tasks.append(self._return_none())

        if self.vlg:
            tasks.append(self.vlg.predict(image_path))
        else:
            tasks.append(self._return_none())

        # ë³‘ë ¬ ì‹¤í–‰
        cnn_result, ae_result, vlm_result, vlg_result = await asyncio.gather(
            *tasks,
            return_exceptions=True
        )

        # ê²°ê³¼ í†µí•©
        return {
            "image_id": Path(image_path).name,
            "cnn": cnn_result if not isinstance(cnn_result, Exception) else None,
            "autoencoder": ae_result if not isinstance(ae_result, Exception) else None,
            "vlm": vlm_result if not isinstance(vlm_result, Exception) else None,
            "vlg": vlg_result if not isinstance(vlg_result, Exception) else None,
        }

    async def _return_none(self):
        """í”Œë ˆì´ìŠ¤í™€ë”"""
        return None
```

### Threshold ê´€ë¦¬ íë¦„ ì •ë¦¬

```text
[í•™ìŠµ ì‹œ]
1. AutoEncoder í•™ìŠµ ì™„ë£Œ
   â†“
2. Validation ë°ì´í„°ë¡œ ì¬êµ¬ì„± ì˜¤ë¥˜ ê³„ì‚°
   â†“
3. Threshold ê³„ì‚° (mean + k * std)
   â†“
4. threshold.json ì €ì¥
   {
     "threshold": 0.0285,
     "method": "mean_std",
     "k": 2.5,
     "mean_error": 0.0198,
     "std_error": 0.0035
   }
   â†“
5. ëª¨ë¸ (.pt) + threshold.json í•¨ê»˜ ì €ì¥

[ì¶”ë¡  ì‹œ]
1. AEPredictor ì´ˆê¸°í™”
   â†“
2. â­ threshold.json ë¡œë“œ (ìë™)
   â†“
3. ì¶”ë¡  ì‹œ ë¡œë“œëœ threshold ì‚¬ìš©
   â†“
4. í•˜ë“œì½”ë”© âŒ, ì¬í˜„ ê°€ëŠ¥ âœ…
```

---

## ğŸ¯ ì™œ ì´ êµ¬ì¡°ê°€ ì¢‹ì€ê°€?

### 1. ëª…í™•í•œ ì—­í•  ë¶„ë¦¬
- **ì‹¤í—˜ ë‹¨ê³„**: TensorBoardë¡œ í•™ìŠµ ê³¼ì • ì¶”ì 
- **ì„œë¹„ìŠ¤ ë‹¨ê³„**: Web UIë¡œ ìµœì¢… ê²°ê³¼ ì‹œê°í™”

### 2. í™•ì¥ ê°€ëŠ¥ì„±
```text
Phase 1 (í˜„ì¬): ë¡œê·¸ ê¸°ë°˜ Web UI
  - result.json ì½ì–´ì„œ í‘œì‹œ
  - DB ì—†ì´ ë™ì‘

Phase 2 (í™•ì¥): DB ê¸°ë°˜ Web UI
  - result.json â†’ PostgreSQL ì €ì¥
  - Web UIëŠ” ë™ì¼ ì¸í„°í˜ì´ìŠ¤ ìœ ì§€
  - ê²€ìƒ‰, í•„í„°ë§, í†µê³„ ê¸°ëŠ¥ ì¶”ê°€
```

### 3. TensorBoard ë¡œê·¸ê°€ ì§€ì €ë¶„í•´ì§€ì§€ ì•ŠìŒ
- í•™ìŠµìš© ë¡œê·¸ì™€ ì¶”ë¡ ìš© ë¡œê·¸ ì™„ì „ ë¶„ë¦¬
- ì‹¤í—˜ ì¡°ê±´ì´ run ì´ë¦„ì— ëª…ì‹œì ìœ¼ë¡œ í¬í•¨

### 4. DB ì—†ì´ë„ ì›¹ ì‹œê°í™” ê°€ëŠ¥
- íŒŒì¼ ê¸°ë°˜ ì‹œìŠ¤í…œìœ¼ë¡œ ê°„ë‹¨í•˜ê²Œ ì‹œì‘
- ì¶”í›„ DB ë§ˆì´ê·¸ë ˆì´ì…˜ ìš©ì´

---

## âš™ï¸ Config íŒŒì¼ ì„¤ê³„ (YAML)

### 1. CNN í•™ìŠµ Config (training/configs/cnn.yaml)

```yaml
model:
  name: resnet18  # resnet18, resnet50, convnext_tiny
  pretrained: true
  num_classes: 2

training:
  optimizer: Adam
  lr: 0.0001
  batch_size: 32
  epochs: 30
  weight_decay: 0.0001
  device: cuda

criteria:
  loss: CrossEntropy
  early_stopping:
    monitor: val_loss
    patience: 7
    min_delta: 0.001

checkpoint:
  save_best_by: val_f1  # val_f1, val_accuracy
  save_dir: experiments/checkpoints/cnn
```

**ì„¤ê³„ ì˜ë„**:
- Early stoppingê³¼ best model ê¸°ì¤€ ë¶„ë¦¬
- Baseline â†’ í™•ì¥ ì‹¤í—˜ ëª¨ë‘ ë™ì¼ êµ¬ì¡° ì‚¬ìš©
- F1ì„ ê¸°ì¤€ìœ¼ë¡œ ìµœê³  ëª¨ë¸ ì €ì¥

---

### 2. AutoEncoder Config (training/configs/autoencoder.yaml)

```yaml
model:
  type: convolutional_autoencoder
  input_channels: 3
  latent_dim: 128  # Bottleneck size

training:
  optimizer: Adam
  lr: 0.001
  batch_size: 32
  epochs: 50
  device: cuda

criteria:
  loss: MSE

threshold:
  mode: fixed  # fixed, adaptive
  method: mean_std  # mean_std, percentile, f1_max
  k: 2.5  # mean + k * std (methodê°€ mean_stdì¼ ë•Œ)
  percentile: 95  # methodê°€ percentileì¼ ë•Œ

checkpoint:
  save_dir: experiments/checkpoints/autoencoder
  save_threshold: true  # Thresholdë„ í•¨ê»˜ ì €ì¥
```

**ì„¤ê³„ ì˜ë„**:
- ì´ˆê¸° êµ¬í˜„ì€ **fixed threshold** (mean + k * std)
- Threshold ê³„ì‚°ì€ í•™ìŠµ ì¢…ë£Œ í›„ 1íšŒ ìˆ˜í–‰
- Phase 2ì—ì„œ adaptive (f1_max) ë°©ì‹ìœ¼ë¡œ í™•ì¥ ê°€ëŠ¥

---

### 3. Evaluation Config (training/configs/evaluation.yaml)

```yaml
metrics:
  primary: f1  # ëª¨ë“  ì˜ì‚¬ê²°ì •ì˜ ê¸°ì¤€
  secondary:
    - accuracy
    - precision
    - recall
    - roc_auc

cnn:
  decision_metric: f1

autoencoder:
  threshold_metric: f1  # Threshold ê²°ì • ì‹œ ìµœì í™”í•  ì§€í‘œ

reporting:
  save_confusion_matrix: true
  save_roc_curve: true
  save_dir: experiments/results
```

**ì„¤ê³„ ì˜ë„**:
- **F1-score**ë¥¼ ëª¨ë“  ì˜ì‚¬ê²°ì •ì˜ ê¸°ì¤€ìœ¼ë¡œ ì‚¬ìš©
- AccuracyëŠ” ì°¸ê³  ì§€í‘œë¡œë§Œ í™œìš©
- í´ë˜ìŠ¤ ë¶ˆê· í˜• ëŒ€ì‘

---

### 4. Logging Config (training/configs/logging.yaml)

```yaml
logging:
  save_train_log: true
  save_inference_log: false  # ì¶”ë¡  ë¡œê·¸ëŠ” Backendì—ì„œ ê´€ë¦¬
  log_level: INFO

paths:
  train_logs: experiments/logs/train_logs/
  inference_logs: experiments/logs/inference_logs/  # Backendì—ì„œ ì‚¬ìš©

format:
  train: csv  # epoch, train_loss, val_loss, val_f1, val_accuracy
  inference: json  # ì „ì²´ ì¶”ë¡  ê²°ê³¼

tensorboard:
  enabled: true
  log_dir: experiments/logs/tensorboard/  # â­ TensorBoard ì „ìš© ê²½ë¡œ
  run_name_format: "{model}_{key_params}"  # ì˜ˆ: resnet18_lr1e-4_bs32
  log_scalars: true  # Loss, F1, Accuracy
  log_images: true   # AutoEncoder ì¬êµ¬ì„± ê²°ê³¼
  log_histograms: true  # ì¬êµ¬ì„± ì˜¤ë¥˜ ë¶„í¬ (Threshold ê²°ì •ìš©)
  log_embeddings: false  # Phase 2

results:
  save_dir: experiments/results/  # â­ Web UIìš© ê²°ê³¼ (job_id ê¸°ë°˜)
  save_visualization: true  # bbox overlay ë“± ì´ë¯¸ì§€ ì €ì¥
```

**ì„¤ê³„ ì˜ë„**:
- **í•™ìŠµ ë¡œê·¸**: CSV (ê°„ë‹¨, ê°€ë…ì„±) â†’ `experiments/logs/train_logs/`
- **ì¶”ë¡  ë¡œê·¸**: JSON (êµ¬ì¡°í™”, API í˜¸í™˜) â†’ `experiments/logs/inference_logs/`
- **TensorBoard**: í•™ìŠµ ì‹œì—ë§Œ ì‚¬ìš© â†’ `experiments/logs/tensorboard/`
- **Web ê²°ê³¼**: job_id ê¸°ë°˜ â†’ `experiments/results/job_xxx/`

---

## ğŸ“Š Evaluation ê¸°ì¤€

### 1. í‰ê°€ ì§€í‘œ ìš°ì„ ìˆœìœ„

| ì§€í‘œ | ì—­í•  | ì‚¬ìš©ì²˜ |
|-----|-----|--------|
| **F1 Score** | ì£¼ í‰ê°€ ì§€í‘œ | ëª¨ë¸ ì €ì¥, Threshold ê²°ì •, ìµœì¢… í‰ê°€ |
| Accuracy | ì°¸ê³  ì§€í‘œ | ë¦¬í¬íŠ¸ìš© |
| Precision | ì°¸ê³  ì§€í‘œ | ë¶ˆëŸ‰ ê²€ì¶œ ì •í™•ë„ ë¶„ì„ |
| **Recall** | ì¤‘ìš” ì§€í‘œ | ë¶ˆëŸ‰ ë¯¸íƒ ìµœì†Œí™” í™•ì¸ |
| ROC-AUC | ì°¸ê³  ì§€í‘œ | ëª¨ë¸ ê°„ ë¹„êµ |

### 2. í‰ê°€ íë¦„

```text
í•™ìŠµ
 â†“
val_lossë¡œ Early Stopping
 â†“
val_F1 ìµœê³  ëª¨ë¸ ì €ì¥
 â†“
ê³ ì • Threshold ì ìš© (AutoEncoder)
 â†“
í…ŒìŠ¤íŠ¸ì…‹ì—ì„œ Accuracy / F1 / Recall / ROC-AUC ë¦¬í¬íŠ¸
```

### 3. CNN í‰ê°€ ê¸°ì¤€

```python
# training/evaluation/metrics.py
def evaluate_cnn(model, test_loader):
    """
    CNN í‰ê°€
    - ì£¼ ì§€í‘œ: F1 Score
    - Early Stopping: val_loss
    - Best Model: val_f1
    """
    metrics = {
        'accuracy': accuracy_score(y_true, y_pred),
        'f1': f1_score(y_true, y_pred),
        'precision': precision_score(y_true, y_pred),
        'recall': recall_score(y_true, y_pred),
        'roc_auc': roc_auc_score(y_true, y_proba)
    }
    return metrics
```

### 4. AutoEncoder í‰ê°€ ê¸°ì¤€

```python
# training/evaluation/threshold_finder.py
def find_threshold(ae_model, val_loader, method='mean_std', k=2.5):
    """
    Threshold ê³„ì‚°
    - Phase 1: mean + k * std (ê³ ì •)
    - Phase 2: F1 ìµœëŒ€í™” (ì ì‘í˜•)
    """
    reconstruction_errors = []
    for img in val_loader:
        reconstructed = ae_model(img)
        error = mse(img, reconstructed)
        reconstruction_errors.append(error)

    if method == 'mean_std':
        threshold = np.mean(reconstruction_errors) + k * np.std(reconstruction_errors)
    elif method == 'f1_max':
        # Grid searchë¡œ F1 ìµœëŒ€í™”í•˜ëŠ” threshold ì°¾ê¸°
        threshold = find_optimal_threshold_by_f1(reconstruction_errors, labels)

    return threshold
```

---

## ğŸ“ Logging ì „ëµ

### 1. í•™ìŠµ ë¡œê·¸ (CSV)

**í˜•ì‹**: `experiments/logs/train/cnn_ct_train.csv`

```csv
epoch,train_loss,val_loss,val_f1,val_accuracy,val_recall
1,0.523,0.412,0.78,0.82,0.75
2,0.401,0.389,0.81,0.84,0.79
3,0.356,0.375,0.83,0.86,0.82
```

**í™œìš©**:
- í•™ìŠµ ê³¼ì • ì¶”ì 
- ê·¸ë˜í”„ ìƒì„± (Loss curve, Metric curve)
- Early stopping íŒë‹¨ ê·¼ê±°

### 2. ì¶”ë¡  ë¡œê·¸ (JSON)

**í˜•ì‹**: `experiments/logs/inference/batch_results_20250101.json`

```json
[
  {
    "image_id": "img_001.jpg",
    "timestamp": "2025-01-01T10:30:00",
    "cnn": {
      "pred": "defect",
      "confidence": 0.91
    },
    "autoencoder": {
      "score": 0.034,
      "threshold": 0.028,
      "is_anomaly": true
    },
    "vlm": {
      "judgement": "defect",
      "reason": "í‘œë©´ì— í¬ë™ ë°œê²¬"
    },
    "vlg": {
      "bboxes": [{"x": 10, "y": 20, "w": 50, "h": 60}],
      "scores": [0.87]
    }
  }
]
```

**í™œìš©**:
- ì›¹ ì¶”ë¡  ê²°ê³¼ ì €ì¥
- ë°°ì¹˜ ì²˜ë¦¬ ì´ë ¥ ê´€ë¦¬
- ì¬í˜„ì„± í™•ë³´

### 3. TensorBoard (í•™ìŠµìš©)

**ë¡œê¹… í•­ëª©**:
- Scalars: Loss, F1, Accuracy, Recall
- Images: AutoEncoder ì¬êµ¬ì„± ê²°ê³¼ (ì›ë³¸ vs ì¬êµ¬ì„±)
- Histograms: ì¬êµ¬ì„± ì˜¤ë¥˜ ë¶„í¬ (Threshold ê²°ì •ìš©)
- Confusion Matrix: CNN ë¶„ë¥˜ ê²°ê³¼

**TensorBoard Logger ì´ˆê¸°í™” (run ì´ë¦„ ìë™ ìƒì„±)**:
```python
# training/visualization/tensorboard_logger.py
from torch.utils.tensorboard import SummaryWriter
from pathlib import Path

class TensorBoardLogger:
    def __init__(self, config):
        """
        TensorBoard Logger ì´ˆê¸°í™”
        - run ì´ë¦„: <model>_<key_params>
        """
        # Run ì´ë¦„ ìƒì„±
        run_name = self._generate_run_name(config)

        # TensorBoard Writer ìƒì„±
        log_dir = Path(config['tensorboard']['log_dir']) / config['model']['name'] / run_name
        self.writer = SummaryWriter(log_dir=str(log_dir))

    def _generate_run_name(self, config):
        """
        ì‹¤í—˜ ì¡°ê±´ ê¸°ë°˜ run ì´ë¦„ ìƒì„±
        ì˜ˆ: resnet18_lr1e-4_bs32
        """
        model_name = config['model']['name']
        lr = config['training']['lr']
        bs = config['training']['batch_size']

        run_name = f"{model_name}_lr{lr}_bs{bs}"

        # ì¶”ê°€ íŒŒë¼ë¯¸í„° (ì„ íƒì )
        if 'weight_decay' in config['training'] and config['training']['weight_decay'] > 0:
            wd = config['training']['weight_decay']
            run_name += f"_wd{wd}"

        # AutoEncoder: k ê°’ ì¶”ê°€
        if 'threshold' in config and 'k' in config['threshold']:
            k = config['threshold']['k']
            run_name += f"_k{k}"

        return run_name

    def log_scalars(self, epoch, train_loss, val_loss, val_f1):
        self.writer.add_scalar('train/loss', train_loss, epoch)
        self.writer.add_scalar('val/loss', val_loss, epoch)
        self.writer.add_scalar('val/f1', val_f1, epoch)

    def close(self):
        self.writer.close()
```

**ì‹¤í–‰ ì˜ˆì‹œ**:
```bash
# í•™ìŠµ ì‹œì‘ â†’ TensorBoard ìë™ ë¡œê¹…
python training/scripts/train_cnn_ct.py
# â†’ experiments/logs/tensorboard/resnet18/resnet18_lr0.0001_bs32/

# TensorBoard ì‹¤í–‰
tensorboard --logdir experiments/logs/tensorboard
# ë¸Œë¼ìš°ì €ì—ì„œ http://localhost:6006 ì ‘ì†
# â†’ "resnet18_lr0.0001_bs32" run ì´ë¦„ìœ¼ë¡œ í‘œì‹œ
```

---

## ğŸšï¸ Threshold ê´€ë¦¬ ì „ëµ

### Phase 1: ê³ ì • Threshold (í˜„ì¬)

**ë°©ì‹**: `mean + k * std`

```python
# training/evaluation/threshold_finder.py
def compute_fixed_threshold(val_errors, k=2.5):
    """
    ê³ ì • Threshold ê³„ì‚°
    - ê²€ì¦ ë°ì´í„°ì˜ ì¬êµ¬ì„± ì˜¤ë¥˜ ë¶„í¬ ê¸°ë°˜
    - mean + k * std
    """
    threshold = np.mean(val_errors) + k * np.std(val_errors)
    return threshold
```

**ì €ì¥ í˜•ì‹**: `experiments/checkpoints/autoencoder/ae_rgb_threshold.json`

```json
{
  "threshold": 0.0285,
  "method": "mean_std",
  "k": 2.5,
  "computed_from": "validation_set",
  "num_samples": 520,
  "mean_error": 0.0198,
  "std_error": 0.0035
}
```

**íŠ¹ì§•**:
- ì¬í˜„ì„±ê³¼ ë¹„êµ ì‹¤í—˜ì— ìµœì 
- Configë¡œ k ê°’ ì¡°ì ˆ ê°€ëŠ¥
- í•™ìŠµ í›„ 1íšŒë§Œ ê³„ì‚°

### Phase 2: ì ì‘í˜• Threshold (í™•ì¥)

**ë°©ì‹**: F1 ìµœëŒ€í™”

```yaml
# training/configs/autoencoder.yaml (Phase 2)
threshold:
  mode: adaptive
  method: f1_max
```

```python
def find_adaptive_threshold(val_errors, val_labels):
    """
    F1 ìµœëŒ€í™”í•˜ëŠ” Threshold ì°¾ê¸°
    - Grid search
    """
    best_f1 = 0
    best_threshold = 0

    for threshold in np.linspace(min(val_errors), max(val_errors), 100):
        predictions = (val_errors > threshold).astype(int)
        f1 = f1_score(val_labels, predictions)
        if f1 > best_f1:
            best_f1 = f1
            best_threshold = threshold

    return best_threshold
```

**ì ìš© ì‹œì **: ì‹¤í—˜ ê²°ê³¼ ì¶©ë¶„íˆ ìŒ“ì¸ ì´í›„

---

## ğŸ”§ Config ë¡œë”© ì˜ˆì‹œ

```python
# training/config/config_loader.py
import yaml
from pathlib import Path

class ConfigLoader:
    """YAML Config ë¡œë”"""

    @staticmethod
    def load(config_name: str):
        """
        Config íŒŒì¼ ë¡œë“œ
        Args:
            config_name: 'cnn', 'autoencoder', 'evaluation', 'logging'
        """
        config_path = Path(__file__).parent.parent / 'configs' / f'{config_name}.yaml'

        with open(config_path, 'r') as f:
            config = yaml.safe_load(f)

        return config

# ì‚¬ìš© ì˜ˆì‹œ
# training/scripts/train_cnn_ct.py
from config.config_loader import ConfigLoader

config = ConfigLoader.load('cnn')

model = ResNet(
    name=config['model']['name'],
    pretrained=config['model']['pretrained'],
    num_classes=config['model']['num_classes']
)

optimizer = torch.optim.Adam(
    model.parameters(),
    lr=config['training']['lr'],
    weight_decay=config['training']['weight_decay']
)
```

---

## ğŸ“‹ í•µì‹¬ ìš”ì•½

### Config ê´€ë¦¬
- âœ… ëª¨ë“  ì‹¤í—˜ ì„¤ì •ì€ YAML íŒŒì¼ë¡œ ê´€ë¦¬
- âœ… í•˜ë“œì½”ë”© ê¸ˆì§€ â†’ ì¬í˜„ì„± í™•ë³´
- âœ… Baseline â†’ í™•ì¥ ì‹¤í—˜ ë™ì¼ êµ¬ì¡°

### Evaluation ê¸°ì¤€
- âœ… **F1 Score = ì£¼ í‰ê°€ ì§€í‘œ**
- âœ… Accuracy = ì°¸ê³  ì§€í‘œ
- âœ… Recall = ë¶ˆëŸ‰ ë¯¸íƒ ìµœì†Œí™” í™•ì¸

### Logging ì „ëµ
- âœ… í•™ìŠµ ë¡œê·¸: CSV (ê°„ë‹¨, ê°€ë…ì„±)
- âœ… ì¶”ë¡  ë¡œê·¸: JSON (êµ¬ì¡°í™”, API í˜¸í™˜)
- âœ… TensorBoard: í•™ìŠµ ê³¼ì • ì‹œê°í™”

### Threshold ê´€ë¦¬
- âœ… Phase 1: ê³ ì • (mean + k * std)
- âœ… Phase 2: ì ì‘í˜• (F1 ìµœëŒ€í™”)
- âœ… **ëª¨ë¸ê³¼ í•¨ê»˜ ì €ì¥ í•„ìˆ˜**

---

## ğŸ¨ Data Transform ì„¤ê³„ (CT vs RGB ê³µí†µí™”)

### ë¬¸ì œì 
CT ë°ì´í„°ì™€ RGB ë°ì´í„°ëŠ” ì „ì²˜ë¦¬ ë°©ì‹ì´ ì™„ì „íˆ ë‹¤ë¦„:

| í•­ëª© | CT ë°ì´í„° | RGB ë°ì´í„° |
|------|----------|-----------|
| **ì±„ë„** | ê·¸ë ˆì´ìŠ¤ì¼€ì¼ (1ì±„ë„) | ì»¬ëŸ¬ (3ì±„ë„) |
| **ì •ê·œí™”** | CT íŠ¹í™” ì •ê·œí™” (HU ê°’ ë“±) | ImageNet ì •ê·œí™” |
| **ì „ì²˜ë¦¬** | ìœˆë„ì‰, í´ë¦¬í•‘ | ì¼ë°˜ì ì¸ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ |
| **Data Augmentation** | íšŒì „, Flipë§Œ | ì»¬ëŸ¬ jitter, ë°ê¸° ì¡°ì • ë“± |

â†’ **í•´ê²°ì±…**: Factory íŒ¨í„´ + Config ê¸°ë°˜ìœ¼ë¡œ modalityë³„ Transformì„ ìë™ ì„ íƒ

---

### ì„¤ê³„ ì›ì¹™

1. **ê³µí†µ ì¸í„°í˜ì´ìŠ¤**: `get_transforms(modality, mode)` í•¨ìˆ˜ë¡œ í†µì¼
2. **Config ê¸°ë°˜**: YAML íŒŒì¼ì—ì„œ augmentation ì„¤ì • ë¡œë“œ
3. **ëª¨ë“ˆí™”**: Train/Val/Test ë³„ë¡œ ë‹¤ë¥¸ transform ì ìš©
4. **ì¬ì‚¬ìš©ì„±**: Datasetì—ì„œ modalityë§Œ ì „ë‹¬í•˜ë©´ ìë™ ì„ íƒ

---

### êµ¬í˜„ ì½”ë“œ

#### 1. Transform Factory (`training/data/transforms.py`)

```python
# training/data/transforms.py
import torch
from torchvision import transforms
from typing import Literal

class CTTransforms:
    """CT ë°ì´í„° ì „ìš© Transform"""

    @staticmethod
    def get_train_transforms(config):
        """CT í•™ìŠµìš© Transform"""
        return transforms.Compose([
            transforms.Resize((config['data']['image_size'], config['data']['image_size'])),
            transforms.RandomHorizontalFlip(p=0.5),
            transforms.RandomVerticalFlip(p=0.5),
            transforms.RandomRotation(degrees=15),
            # CTëŠ” ì»¬ëŸ¬ augmentation ì œì™¸
            transforms.ToTensor(),
            # CT ì „ìš© ì •ê·œí™” (í‰ê·  0.5, í‘œì¤€í¸ì°¨ 0.5)
            transforms.Normalize(mean=[0.5], std=[0.5])  # ë‹¨ì¼ ì±„ë„
        ])

    @staticmethod
    def get_val_transforms(config):
        """CT ê²€ì¦/í…ŒìŠ¤íŠ¸ìš© Transform (augmentation ì œì™¸)"""
        return transforms.Compose([
            transforms.Resize((config['data']['image_size'], config['data']['image_size'])),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.5], std=[0.5])
        ])

    @staticmethod
    def get_test_transforms(config):
        """CT í…ŒìŠ¤íŠ¸ìš© (Valê³¼ ë™ì¼)"""
        return CTTransforms.get_val_transforms(config)


class RGBTransforms:
    """RGB ë°ì´í„° ì „ìš© Transform"""

    @staticmethod
    def get_train_transforms(config):
        """RGB í•™ìŠµìš© Transform"""
        return transforms.Compose([
            transforms.Resize((config['data']['image_size'], config['data']['image_size'])),
            transforms.RandomHorizontalFlip(p=0.5),
            transforms.RandomVerticalFlip(p=0.5),
            transforms.RandomRotation(degrees=15),
            # RGB ì „ìš© augmentation
            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.1, hue=0.05),
            transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),
            transforms.ToTensor(),
            # ImageNet ì •ê·œí™” (3ì±„ë„)
            transforms.Normalize(
                mean=[0.485, 0.456, 0.406],
                std=[0.229, 0.224, 0.225]
            )
        ])

    @staticmethod
    def get_val_transforms(config):
        """RGB ê²€ì¦/í…ŒìŠ¤íŠ¸ìš© Transform"""
        return transforms.Compose([
            transforms.Resize((config['data']['image_size'], config['data']['image_size'])),
            transforms.ToTensor(),
            transforms.Normalize(
                mean=[0.485, 0.456, 0.406],
                std=[0.229, 0.224, 0.225]
            )
        ])

    @staticmethod
    def get_test_transforms(config):
        """RGB í…ŒìŠ¤íŠ¸ìš© (Valê³¼ ë™ì¼)"""
        return RGBTransforms.get_val_transforms(config)


# â­ Factory í•¨ìˆ˜ (í•µì‹¬)
def get_transforms(
    modality: Literal['ct', 'rgb'],
    mode: Literal['train', 'val', 'test'],
    config: dict
):
    """
    Modalityì™€ Modeì— ë”°ë¼ ì ì ˆí•œ Transform ë°˜í™˜

    Args:
        modality: 'ct' ë˜ëŠ” 'rgb'
        mode: 'train', 'val', 'test'
        config: YAML config ë”•ì…”ë„ˆë¦¬

    Returns:
        transforms.Compose ê°ì²´

    Example:
        >>> config = ConfigLoader.load('cnn')
        >>> train_transform = get_transforms('ct', 'train', config)
        >>> val_transform = get_transforms('ct', 'val', config)
    """
    if modality == 'ct':
        transform_class = CTTransforms
    elif modality == 'rgb':
        transform_class = RGBTransforms
    else:
        raise ValueError(f"Unknown modality: {modality}. Must be 'ct' or 'rgb'.")

    if mode == 'train':
        return transform_class.get_train_transforms(config)
    elif mode == 'val':
        return transform_class.get_val_transforms(config)
    elif mode == 'test':
        return transform_class.get_test_transforms(config)
    else:
        raise ValueError(f"Unknown mode: {mode}. Must be 'train', 'val', or 'test'.")
```

---

#### 2. Datasetì—ì„œ ì‚¬ìš© (`training/data/dataset.py`)

```python
# training/data/dataset.py
from torch.utils.data import Dataset
from PIL import Image
from .transforms import get_transforms

class BatteryDataset(Dataset):
    """ë°°í„°ë¦¬ ë°ì´í„°ì…‹ (CT/RGB ê³µí†µ)"""

    def __init__(self, csv_path, modality, mode, config):
        """
        Args:
            csv_path: ë°ì´í„° CSV ê²½ë¡œ
            modality: 'ct' or 'rgb'
            mode: 'train', 'val', 'test'
            config: YAML config
        """
        self.data = self._load_csv(csv_path)
        self.modality = modality
        self.mode = mode

        # â­ Transform ìë™ ì„ íƒ
        self.transform = get_transforms(modality, mode, config)

    def __getitem__(self, idx):
        img_path = self.data.iloc[idx]['image_path']
        label = self.data.iloc[idx]['label']

        # ì´ë¯¸ì§€ ë¡œë“œ
        image = Image.open(img_path)

        # CTëŠ” L ëª¨ë“œ (ê·¸ë ˆì´ìŠ¤ì¼€ì¼), RGBëŠ” RGB ëª¨ë“œ
        if self.modality == 'ct':
            image = image.convert('L')  # ê·¸ë ˆì´ìŠ¤ì¼€ì¼
        else:
            image = image.convert('RGB')

        # Transform ì ìš© (ìë™ìœ¼ë¡œ modalityë³„ ì²˜ë¦¬)
        if self.transform:
            image = self.transform(image)

        return image, label
```

---

#### 3. DataLoader íŒ©í† ë¦¬ (`training/data/dataloader.py`)

```python
# training/data/dataloader.py
from torch.utils.data import DataLoader
from .dataset import BatteryDataset

def get_dataloader(csv_path, modality, mode, config, shuffle=True):
    """
    DataLoader ìƒì„± (modalityë³„ ìë™ ì²˜ë¦¬)

    Args:
        csv_path: CSV ê²½ë¡œ
        modality: 'ct' or 'rgb'
        mode: 'train', 'val', 'test'
        config: YAML config
        shuffle: ì…”í”Œ ì—¬ë¶€

    Returns:
        DataLoader ê°ì²´
    """
    dataset = BatteryDataset(
        csv_path=csv_path,
        modality=modality,
        mode=mode,
        config=config
    )

    return DataLoader(
        dataset,
        batch_size=config['training']['batch_size'],
        shuffle=shuffle,
        num_workers=config['training'].get('num_workers', 4),
        pin_memory=True
    )
```

---

#### 4. í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ì—ì„œ ì‚¬ìš©

```python
# models/ct_cnn/train.py
from training.config.config_loader import ConfigLoader
from training.data.dataloader import get_dataloader

# Config ë¡œë“œ
config = ConfigLoader.load('cnn')

# â­ DataLoader ìƒì„± (modalityì™€ modeë§Œ ì „ë‹¬)
train_loader = get_dataloader(
    csv_path='training/data/splits/ct_cnn/train.txt',
    modality='ct',  # CT ë°ì´í„°
    mode='train',   # í•™ìŠµ ëª¨ë“œ (augmentation ì ìš©)
    config=config,
    shuffle=True
)

val_loader = get_dataloader(
    csv_path='training/data/splits/ct_cnn/val.txt',
    modality='ct',
    mode='val',     # ê²€ì¦ ëª¨ë“œ (augmentation ì œì™¸)
    config=config,
    shuffle=False
)

test_loader = get_dataloader(
    csv_path='training/data/splits/ct_cnn/test.txt',
    modality='ct',
    mode='test',    # í…ŒìŠ¤íŠ¸ ëª¨ë“œ
    config=config,
    shuffle=False
)
```

---

### Config íŒŒì¼ ì„¤ì •

#### CNN Config (`training/configs/cnn.yaml`)
```yaml
data:
  image_size: 512
  modality: ct  # â­ modality ëª…ì‹œ

training:
  batch_size: 32
  num_workers: 4
```

#### AutoEncoder Config (`training/configs/autoencoder.yaml`)
```yaml
data:
  image_size: 256
  modality: rgb  # â­ RGB AutoEncoder

training:
  batch_size: 32
  num_workers: 4
```

---

### í•µì‹¬ ì¥ì 

#### 1. **ë‹¨ì¼ ì¸í„°í˜ì´ìŠ¤**
```python
# CTë“  RGBë“  ë™ì¼í•œ ë°©ì‹
transform = get_transforms(modality='ct', mode='train', config)
```

#### 2. **ìë™ ì²˜ë¦¬**
- Datasetì´ modalityë§Œ ë°›ìœ¼ë©´ ìë™ìœ¼ë¡œ ì ì ˆí•œ transform ì ìš©
- ê°œë°œìê°€ ì¼ì¼ì´ transform ì„ íƒí•  í•„ìš” ì—†ìŒ

#### 3. **í™•ì¥ ê°€ëŠ¥**
```python
# ìƒˆ modality ì¶”ê°€ ì‹œ
class XRayTransforms:
    @staticmethod
    def get_train_transforms(config):
        # X-Ray ì „ìš© ì „ì²˜ë¦¬
        pass

# Factory í•¨ìˆ˜ì— ì¶”ê°€ë§Œ í•˜ë©´ ë¨
if modality == 'xray':
    transform_class = XRayTransforms
```

#### 4. **Config ê¸°ë°˜**
- `image_size`, `batch_size` ë“± configì—ì„œ ê´€ë¦¬
- ì½”ë“œ ìˆ˜ì • ì—†ì´ ì‹¤í—˜ ê°€ëŠ¥

#### 5. **ì¬í˜„ì„±**
- Train/Val/Test ë¶„ë¦¬ ëª…í™•
- Val/TestëŠ” augmentation ì œì™¸ (ë™ì¼ ê²°ê³¼)

---

### ì£¼ì˜ì‚¬í•­

#### 1. **ì±„ë„ ìˆ˜ ë¶ˆì¼ì¹˜ ë°©ì§€**
```python
# CT: 1ì±„ë„ â†’ 3ì±„ë„ ë³µì œ (Pretrained ëª¨ë¸ ì‚¬ìš© ì‹œ)
if self.modality == 'ct' and self.use_pretrained:
    image = image.convert('RGB')  # L â†’ RGB ë³€í™˜
```

#### 2. **ì •ê·œí™” ê°’ ê²€ì¦**
```python
# CT ë°ì´í„° ì •ê·œí™” í›„ ë²”ìœ„ í™•ì¸
assert image.min() >= -1.0 and image.max() <= 1.0
```

#### 3. **Augmentation ê°•ë„ ì¡°ì ˆ**
```yaml
# training/configs/cnn.yaml
augmentation:
  rotation_degrees: 15
  flip_prob: 0.5
  color_jitter: false  # CTëŠ” ë¹„í™œì„±í™”
```

---

## ğŸ¯ Grad-CAM í†µí•© ê³„íš (ëª¨ë¸ ê°„ ê³µì • ë¹„êµ)

### ë°°ê²½ ë° ëª©ì 
í˜„ì¬ í”„ë¡œì íŠ¸ëŠ” **CNN/AutoEncoder vs VLM/VLG** ë¹„êµë¥¼ ëª©í‘œë¡œ í•˜ì§€ë§Œ, ì¶œë ¥ í˜•ì‹ì´ ë‹¤ë¦„:
- **CNN/AE**: ë¶„ë¥˜ë§Œ (ìœ„ì¹˜ ì •ë³´ âŒ)
- **VLM/VLG**: ë¶„ë¥˜ + ìœ„ì¹˜ ì •ë³´ (í…ìŠ¤íŠ¸ ë˜ëŠ” BBox âœ…)

â†’ **í•´ê²°ì±…**: CNNì— Grad-CAMì„ ì¶”ê°€í•˜ì—¬ ëª¨ë“  ëª¨ë¸ì´ **ìœ„ì¹˜ ì •ë³´**ë¥¼ ì œê³µí•˜ë„ë¡ í†µì¼

### êµ¬í˜„ ì „ëµ

#### 1. Grad-CAM ëª¨ë“ˆ (`models/ct_cnn/gradcam.py`)
```python
from pytorch_grad_cam import GradCAM
from pytorch_grad_cam.utils.model_targets import BinaryClassifierOutputTarget

class GradCAMGenerator:
    """Grad-CAM íˆíŠ¸ë§µ ìƒì„±ê¸°"""

    def __init__(self, model, target_layer):
        self.model = model
        self.cam = GradCAM(model=model, target_layers=[target_layer])

    def generate(self, image_tensor, target_class=1):
        """
        Grad-CAM íˆíŠ¸ë§µ ìƒì„±

        Args:
            image_tensor: ì…ë ¥ ì´ë¯¸ì§€ í…ì„œ (1, C, H, W)
            target_class: íƒ€ê²Ÿ í´ë˜ìŠ¤ (0: normal, 1: defect)

        Returns:
            heatmap: numpy array (H, W) ë²”ìœ„ [0, 1]
        """
        targets = [BinaryClassifierOutputTarget(target_class)]
        heatmap = self.cam(input_tensor=image_tensor, targets=targets)
        return heatmap[0]  # Batch dimension ì œê±°
```

#### 2. BBox ì¶”ì¶œ (`models/ct_cnn/bbox_extractor.py`)
```python
import cv2
import numpy as np

def extract_bboxes_from_heatmap(heatmap, threshold=0.5, min_area=100):
    """
    Grad-CAM íˆíŠ¸ë§µì—ì„œ ì—¬ëŸ¬ ê°œì˜ Bounding Box ì¶”ì¶œ

    Args:
        heatmap: Grad-CAM íˆíŠ¸ë§µ (H, W) ë²”ìœ„ [0, 1]
        threshold: ì´ì§„í™” ì„ê³„ê°’ (0.5 = íˆíŠ¸ë§µ ìƒìœ„ 50%)
        min_area: ìµœì†Œ ì˜ì—­ í¬ê¸° (í”½ì…€)

    Returns:
        bboxes: [{"x": int, "y": int, "w": int, "h": int, "score": float}, ...]
    """
    # 1. ì´ì§„í™”
    binary_mask = (heatmap > threshold).astype(np.uint8)

    # 2. Connected Components ë¶„ì„
    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(
        binary_mask, connectivity=8
    )

    bboxes = []
    for i in range(1, num_labels):  # 0ì€ ë°°ê²½
        x, y, w, h, area = stats[i]

        # ì‘ì€ ì˜ì—­ í•„í„°ë§
        if area < min_area:
            continue

        # í•´ë‹¹ ì˜ì—­ì˜ í‰ê·  íˆíŠ¸ë§µ ê°’ = confidence score
        region_mask = (labels == i)
        score = float(heatmap[region_mask].mean())

        bboxes.append({
            "x": int(x),
            "y": int(y),
            "w": int(w),
            "h": int(h),
            "score": score
        })

    # Confidence ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
    bboxes.sort(key=lambda b: b["score"], reverse=True)
    return bboxes
```

#### 3. ì‹œê°í™” (`models/ct_cnn/visualizer.py`)
```python
import cv2
import numpy as np
from pathlib import Path
from PIL import Image

def visualize_gradcam(original_image, heatmap, bboxes, image_name, save_dir):
    """
    Grad-CAM ì‹œê°í™” (3ê°€ì§€ ì´ë¯¸ì§€ ìƒì„±)

    Args:
        original_image: ì›ë³¸ ì´ë¯¸ì§€ (H, W, C) numpy array
        heatmap: Grad-CAM íˆíŠ¸ë§µ (H, W) ë²”ìœ„ [0, 1]
        bboxes: BBox ë¦¬ìŠ¤íŠ¸
        image_name: ì´ë¯¸ì§€ íŒŒì¼ëª… (í™•ì¥ì ì œì™¸)
        save_dir: ì €ì¥ ë””ë ‰í† ë¦¬

    Returns:
        {
            "heatmap": "path/to/heatmap.jpg",
            "overlay": "path/to/overlay.jpg",
            "heatmap_overlay": "path/to/heatmap_overlay.jpg"
        }
    """
    save_dir = Path(save_dir)
    save_dir.mkdir(parents=True, exist_ok=True)

    # 1. íˆíŠ¸ë§µ ì»¬ëŸ¬ë§µ ì ìš© (JET)
    heatmap_uint8 = (heatmap * 255).astype(np.uint8)
    heatmap_colored = cv2.applyColorMap(heatmap_uint8, cv2.COLORMAP_JET)

    # 2. íˆíŠ¸ë§µ ì˜¤ë²„ë ˆì´ (ì›ë³¸ 60% + íˆíŠ¸ë§µ 40%)
    heatmap_overlay = cv2.addWeighted(
        original_image, 0.6,
        heatmap_colored, 0.4,
        0
    )

    # 3. BBox ì˜¤ë²„ë ˆì´
    bbox_overlay = original_image.copy()
    for bbox in bboxes:
        x, y, w, h = bbox["x"], bbox["y"], bbox["w"], bbox["h"]
        score = bbox["score"]

        # ë…¹ìƒ‰ ë°•ìŠ¤ ê·¸ë¦¬ê¸°
        cv2.rectangle(
            bbox_overlay,
            (x, y), (x + w, y + h),
            color=(0, 255, 0),  # ë…¹ìƒ‰
            thickness=3
        )

        # Confidence í‘œì‹œ
        cv2.putText(
            bbox_overlay,
            f"{score:.2f}",
            (x, y - 10),
            cv2.FONT_HERSHEY_SIMPLEX,
            0.6,
            (0, 255, 0),
            2
        )

    # 4. ì €ì¥
    paths = {}

    heatmap_path = save_dir / f"{image_name}_heatmap.jpg"
    cv2.imwrite(str(heatmap_path), heatmap_colored)
    paths["heatmap"] = str(heatmap_path)

    overlay_path = save_dir / f"{image_name}_overlay.jpg"
    cv2.imwrite(str(overlay_path), bbox_overlay)
    paths["overlay"] = str(overlay_path)

    heatmap_overlay_path = save_dir / f"{image_name}_heatmap_overlay.jpg"
    cv2.imwrite(str(heatmap_overlay_path), heatmap_overlay)
    paths["heatmap_overlay"] = str(heatmap_overlay_path)

    return paths
```

### í†µí•© ê²°ê³¼ ë¹„êµ

**ëª¨ë“  ëª¨ë¸ì´ ë™ì¼í•œ ì¶œë ¥ í˜•ì‹**:

| ëª¨ë¸ | ë¶„ë¥˜ | ë¶ˆëŸ‰ ìœ í˜• | ìœ„ì¹˜ ì •ë³´ | ì‹œê°í™” |
|------|------|-----------|-----------|--------|
| **CT CNN** | âœ… defect (0.95) | âœ… 5í´ë˜ìŠ¤ (porosity, resin_overflow ë“±) | âœ… Grad-CAM BBox | âœ… Heatmap + BBox |
| **RGB AE** | âœ… anomaly (score) | âŒ (ì´ìƒ íƒì§€ë§Œ, Binary) | âŒ (ì „ì—­ ì´ìƒ ê°ì§€) | âœ… ì¬êµ¬ì„± ì˜¤ì°¨ ë§µ |
| **VLM** | âœ… defect | âœ… "porosity ê²°í•¨" | âœ… [x:115, y:335, w:55, h:85] | âœ… BBox + í…ìŠ¤íŠ¸ ì„¤ëª… |
| **VLG** | âœ… defect | âœ… Queryë³„ ê²€ì¶œ | âœ… [x:118, y:338, w:52, h:82] | âœ… BBox |

> **ë¶ˆëŸ‰ ìœ í˜• (Defect Types)**:
> - CT 5í´ë˜ìŠ¤: `cell_normal`, `cell_porosity`, `module_normal`, `module_porosity`, `module_resin_overflow`
> - RGB: Binary ì´ìƒíƒì§€ (`normal` vs `defect`)

### í‰ê°€ ì§€í‘œ (ê³µì • ë¹„êµ)

#### 1. ë¶„ë¥˜ ì„±ëŠ¥
- Metric: F1, Precision, Recall, Accuracy
- ëª¨ë“  ëª¨ë¸ ê³µí†µ í‰ê°€

#### 2. ìœ„ì¹˜ ì •í™•ë„ (Localization)
- Metric: **IoU (Intersection over Union)**
- Ground Truth BBoxì™€ ë¹„êµ
- í‰ê°€ ëŒ€ìƒ: CNN (Grad-CAM), VLM (í…ìŠ¤íŠ¸â†’BBox ë³€í™˜), VLG

#### 3. ì¢…í•© í‰ê°€
- **F1@IoU>0.5**: COCO ë°©ì‹
- ë¶„ë¥˜ê°€ ë§ê³  + ìœ„ì¹˜ë„ ë§ì•„ì•¼ True Positive

### ì˜ì¡´ì„± ì¶”ê°€

```txt
# requirements.txtì— ì¶”ê°€
pytorch-grad-cam>=1.4.0
opencv-python>=4.8.0
```

---

## ğŸ“ ë‹¤ìŒ ì‘ì—…

### Phase 1: í´ë” êµ¬ì¡° ë° Config (1ì¼)
1. **í´ë” êµ¬ì¡° ìƒì„±**: `backend/`, `frontend/`, `training/` + `experiments/` í•˜ìœ„ êµ¬ì¡°
2. **Config YAML íŒŒì¼ ì‘ì„±**: cnn.yaml, autoencoder.yaml, evaluation.yaml, logging.yaml
3. **Config Loader êµ¬í˜„**: YAML íŒŒì¼ ë¡œë”© ìœ í‹¸ë¦¬í‹°
4. **Backend ë””ë ‰í† ë¦¬ ì´ˆê¸°í™”**: FastAPI ê¸°ë³¸ êµ¬ì¡° + `__init__.py` íŒŒì¼

### Phase 2: Training ê¸°ë³¸ êµ¬ì¡° (2-3ì¼)
5. **Dataset/DataLoader êµ¬í˜„**: RGB/CT ë°ì´í„° ë¡œë”©
6. **TensorBoard Logger êµ¬í˜„**: run ì´ë¦„ ìë™ ìƒì„± + ìŠ¤ì¹¼ë¼/ì´ë¯¸ì§€ ë¡œê¹…
7. **Evaluation Metrics êµ¬í˜„**: F1, Accuracy, Precision, Recall, ROC-AUC
8. **Threshold Finder êµ¬í˜„**: mean + k * std ë°©ì‹

### Phase 3: ëª¨ë¸ í•™ìŠµ (3-4ì¼)
9. **CNN (CT) í•™ìŠµ**: ResNet18 + Early Stopping + F1 ê¸°ë°˜ ì €ì¥
10. **AutoEncoder (RGB) í•™ìŠµ**: ë¶ˆëŸ‰ ë°ì´í„° ê¸°ë°˜ + Threshold ê³„ì‚°
11. **AutoEncoder (CT) í•™ìŠµ**: ì •ìƒ ë°ì´í„° ê¸°ë°˜ + Threshold ê³„ì‚°
12. **ì²´í¬í¬ì¸íŠ¸ + Threshold ì €ì¥**: `.pt` + `_threshold.json`

### Phase 4: Backend API (2-3ì¼)
13. **Pydantic Schema ì •ì˜**: Request/Response + BoundingBox
14. **CNN/AE Predictor êµ¬í˜„**: ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ + ì¶”ë¡ 
15. **InferencePipeline êµ¬í˜„**: ëª¨ë¸ ë³‘ë ¬ ì‹¤í–‰
16. **Result Saver êµ¬í˜„**: job_id ê¸°ë°˜ ê²°ê³¼ ì €ì¥
17. **FastAPI ì—”ë“œí¬ì¸íŠ¸**: `/infer`, `/infer/batch`, `/upload`, `/models`

### Phase 5: Frontend UI (2-3ì¼)
18. **Streamlit ê¸°ë³¸ UI**: ë ˆì´ì•„ì›ƒ + ì‚¬ì´ë“œë°”
19. **ì´ë¯¸ì§€ ì—…ë¡œë” ì»´í¬ë„ŒíŠ¸**: ë‹¨ì¼/ë°°ì¹˜ ì—…ë¡œë“œ
20. **API í´ë¼ì´ì–¸íŠ¸ êµ¬í˜„**: Backend í˜¸ì¶œ + job_id ìƒì„±
21. **ResultViewer ì»´í¬ë„ŒíŠ¸**: ëª¨ë¸ë³„ íƒ­ (CNN, AE, VLM, VLG)
22. **job_id ê´€ë¦¬**: ì´ì „ ê²°ê³¼ ë¶ˆëŸ¬ì˜¤ê¸° ê¸°ëŠ¥

### Phase 6: VLM/VLG (ì„ íƒì , 3-4ì¼)
23. â¸ï¸ VLM (Qwen3-VL) ë¡œì»¬ ì¶”ë¡ 
24. â¸ï¸ VLG (GroundingDINO) ì—°ë™
25. â¸ï¸ Frontendì— ê²°ê³¼ ì—°ë™

### Phase 7: ê³ ë„í™” (2-3ì¼)
26. â¸ï¸ Anomaly Score íˆìŠ¤í† ê·¸ë¨ (ë°°ì¹˜ ê²°ê³¼ ë¶„ì„)
27. â¸ï¸ Confusion Matrix ì‹œê°í™”
28. â¸ï¸ DB ë§ˆì´ê·¸ë ˆì´ì…˜ (ì„ íƒì )

---

## ğŸ“š í†µí•©ëœ ì„¤ê³„ ë¬¸ì„œ

ë³¸ ë¬¸ì„œ(`implementation_structure.md`)ëŠ” ë‹¤ìŒ ì„¤ê³„ ë¬¸ì„œë“¤ì„ í†µí•©í•˜ì—¬ ì‹¤ì œ êµ¬í˜„ ê°€ëŠ¥í•œ êµ¬ì¡°ë¡œ ë³€í™˜í•œ ìµœì¢… ì„¤ê³„ì„œì…ë‹ˆë‹¤:

### í†µí•© ë¬¸ì„œ ëª©ë¡
1. âœ… **vision_pipeline_design.md**
   - Web ê¸°ë°˜ ëª¨ë¸ ë¹„êµ ì‹œê°í™”
   - FastAPI + Streamlit ì•„í‚¤í…ì²˜
   - JSON Schema í†µí•©

2. âœ… **config_and_evaluation_design.md**
   - YAML ê¸°ë°˜ Config ê´€ë¦¬
   - F1 ì¤‘ì‹¬ í‰ê°€ ì§€í‘œ
   - Threshold ê´€ë¦¬ ì „ëµ
   - CSV/JSON ë¡œê·¸ êµ¬ì¡°

3. âœ… **tensor_board_and_web_visualization_architecture.md**
   - TensorBoard vs Web UI ì—­í•  ë¶„ë¦¬
   - job_id ê¸°ë°˜ ê²°ê³¼ ê´€ë¦¬
   - ì‹¤í—˜(run) ì´ë¦„ ê·œì¹™
   - ë¡œê·¸ ê¸°ë°˜ Web ì‹œê°í™”

### í•µì‹¬ ì„¤ê³„ ì›ì¹™ (í†µí•©)

1. **"ë¹„êµ ì‹¤í—˜ ë‹¨ê³„ì—ì„œëŠ” ë‹¨ìˆœí•˜ê³  ê²°ì •ì ì¸ íŒŒì´í”„ë¼ì¸ì„ ìœ ì§€í•˜ê³ , í•´ì„ê³¼ í™•ì¥ì€ ê²°ê³¼ê°€ ìŒ“ì¸ ì´í›„ì— ìˆ˜í–‰í•œë‹¤."**

2. **"ì½”ë“œëŠ” ê³ ì •í•˜ê³ , ì‹¤í—˜ì€ ì„¤ì •ìœ¼ë¡œ ë°”ê¾¼ë‹¤"**
   - ëª¨ë“  ì‹¤í—˜ ì„¤ì •ì€ YAML íŒŒì¼ë¡œ ê´€ë¦¬
   - ë™ì¼ config â†’ ë™ì¼ ê²°ê³¼ ì¬í˜„ ê°€ëŠ¥

3. **"í•™ìŠµ ê³¼ì •ì€ TensorBoardë¡œ, ìµœì¢… ê²°ê³¼ëŠ” ë¡œê·¸ ê¸°ë°˜ Web UIë¡œ ë³¸ë‹¤."**
   - TensorBoard: í•™ìŠµ ëª¨ë‹ˆí„°ë§ ì „ìš©
   - Web UI: ì¶”ë¡  ê²°ê³¼ ì‹œê°í™” ì „ìš©
   - ë‘ ì‹œìŠ¤í…œì€ ê°™ì€ ë¡œê·¸ë¥¼ ê³µìœ í•˜ì§€ ì•ŠìŒ

4. **"ì‹¤í—˜ì€ ì„¤ì •ìœ¼ë¡œ, íŒë‹¨ì€ ì§€í‘œë¡œ, ê²°ê³¼ëŠ” ë¡œê·¸ë¡œ ë‚¨ê¸´ë‹¤"**
   - F1 Score = ì£¼ í‰ê°€ ì§€í‘œ
   - Threshold = ì„¤ì •ê°’ (ì½”ë“œ ë¡œì§ ì•„ë‹˜)
   - ëª¨ë“  ê²°ê³¼ëŠ” job_id ê¸°ë°˜ìœ¼ë¡œ ì €ì¥

---

**ë³¸ ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë°”ë¡œ êµ¬í˜„ì„ ì‹œì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.**
