# ConvNeXt-Tiny Config (x축 제외 버전)
#
# 기반: cnn_ct_convnext.yaml
# 변경: x축 단면 데이터 제거 (y/z축만 학습)
# 이유: x축에서 결함이 거의 보이지 않아 shortcut 학습 발생
#       x축 포함 98% → x축 제외 시 59%로 폭락하는 문제 해결

# ============================================================
# 클래스 정의
# ============================================================
classes:
  names:
    - cell_normal
    - cell_porosity
    - module_normal
    - module_porosity
    - module_resin_overflow
  num_classes: 5
  class_weights: [1.5, 1.2, 0.8, 1.0, 8.0]

# ============================================================
# 모델 설정
# ============================================================
model:
  name: convnext_tiny       # timm 모델명
  backbone: timm            # timm 라이브러리 사용
  pretrained: true
  num_classes: 5
  dropout: 0.0              # ConvNeXt는 drop_path 사용
  drop_path_rate: 0.1       # Stochastic depth (ConvNeXt 권장)

# ============================================================
# 데이터 설정
# ============================================================
data:
  # Split 파일 경로 (x축 제외)
  train_split: training/data/splits/ct/resize512_no_x/battery_train.txt
  val_split: training/data/splits/ct/resize512_no_x/battery_val.txt
  test_split: training/data/splits/ct/resize512/battery_test.txt

  # 이미지 설정
  image_size: 512
  batch_size: 16            # ConvNeXt 메모리 고려
  num_workers: 4

  # 전처리 옵션
  preprocessed: true        # 전처리된 512 이미지 사용
  use_albumentations: false

  class_balancing:
    enabled: true
    method: weighted_sampler

  augmentation:
    train:
      - RandomHorizontalFlip:
          p: 0.5
      - RandomVerticalFlip:
          p: 0.5
      - RandomRotation:
          degrees: 90
      - RandomAffine:
          degrees: 0
          translate: [0.1, 0.1]
          scale: [0.9, 1.1]
    val: []

# ============================================================
# 학습 설정
# ============================================================
training:
  optimizer: AdamW
  lr: 0.0002               # ConvNeXt 논문 권장 (1e-4 ~ 3e-4)
  weight_decay: 0.05       # ConvNeXt 논문 권장값
  epochs: 100
  device: cuda

  scheduler:
    name: CosineAnnealingLR   # Cosine decay
    T_max: 100                # total epochs
    eta_min: 1e-6

  warmup:
    enabled: true
    epochs: 5                 # 논문 권장: 5 epochs warmup

  gradient_clip: 1.0
  amp: true

# ============================================================
# 손실 함수 및 평가 기준
# ============================================================
criteria:
  loss: CrossEntropyLoss
  use_class_weights: true
  label_smoothing: 0.1

  focal_loss:
    enabled: true
    gamma: 2.0
    alpha: null

  early_stopping:
    enabled: true
    monitor: val_f1_macro
    patience: 7
    min_delta: 0.001
    mode: max

# ============================================================
# 체크포인트 설정
# ============================================================
checkpoint:
  save_dir: models/ct_cnn/checkpoints
  save_best_by: val_f1_macro
  save_last: true
  save_top_k: 3

# ============================================================
# 로깅 설정
# ============================================================
logging:
  tensorboard:
    enabled: true
    log_dir: models/ct_cnn/logs
    log_confusion_matrix: true
    log_per_class_metrics: true

  train_log:
    enabled: true
    save_path: models/ct_cnn/logs/train_convnext_no_x.csv

# ============================================================
# 실험 메타데이터
# ============================================================
experiment:
  name: ct_convnext_tiny_no_x
  description: "ConvNeXt-Tiny (x축 제외) - shortcut 학습 방지, y/z축만 학습"
  seed: 42
